{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network for Image Classification: Application\n",
    "\n",
    "When you finish this, you will have finished the last programming assignment of Week 4, and also the last programming assignment of this course! \n",
    "\n",
    "You will use use the functions you'd implemented in the previous assignment to build a deep network, and apply it to cat vs non-cat classification. Hopefully, you will see an improvement in accuracy relative to your previous logistic regression implementation.  \n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "- Build and apply a deep neural network to supervised learning. \n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import all the packages that you will need during this assignment. \n",
    "- [numpy](www.numpy.org) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a library to plot graphs in Python.\n",
    "- [h5py](http://www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n",
    "- [PIL](http://www.pythonware.com/products/pil/) and [scipy](https://www.scipy.org/) are used here to test your model with your own picture at the end.\n",
    "- dnn_app_utils provides the functions implemented in the \"Building your Deep Neural Network: Step by Step\" assignment to this notebook.\n",
    "- np.random.seed(1) is used to keep all the random function calls consistent. It will help us grade your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v3 import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Dataset\n",
    "\n",
    "You will use the same \"Cat vs non-Cat\" dataset as in \"Logistic Regression as a Neural Network\" (Assignment 2). The model you had built had 70% test accuracy on classifying cats vs non-cats images. Hopefully, your new model will perform a better!\n",
    "\n",
    "**Problem Statement**: You are given a dataset (\"data.h5\") containing:\n",
    "    - a training set of m_train images labelled as cat (1) or non-cat (0)\n",
    "    - a test set of m_test images labelled as cat and non-cat\n",
    "    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB).\n",
    "\n",
    "Let's get more familiar with the dataset. Load the data by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will show you an image in the dataset. Feel free to change the index and re-run the cell multiple times to see other images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 0. It's a non-cat picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 18\n",
    "plt.imshow(train_x_orig[index])\n",
    "\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 209\n",
      "Number of testing examples: 50\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_x_orig shape: (209, 64, 64, 3)\n",
      "train_y shape: (1, 209)\n",
      "test_x_orig shape: (50, 64, 64, 3)\n",
      "test_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset \n",
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "print (\"Number of training examples: \" + str(m_train))\n",
    "print (\"Number of testing examples: \" + str(m_test))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_x_orig shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_y shape: \" + str(train_y.shape))\n",
    "print (\"test_x_orig shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, you reshape and standardize the images before feeding them to the network. The code is given in the cell below.\n",
    "\n",
    "<img src=\"images/imvectorkiank.png\" style=\"width:450px;height:300px;\">\n",
    "\n",
    "<caption><center> <u>Figure 1</u>: Image to vector conversion. <br> </center></caption>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$12,288$ equals $64 \\times 64 \\times 3$ which is the size of one reshaped image vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Architecture of your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you are familiar with the dataset, it is time to build a deep neural network to distinguish cat images from non-cat images.\n",
    "\n",
    "You will build two different models:\n",
    "- A 2-layer neural network\n",
    "- An L-layer deep neural network\n",
    "\n",
    "You will then compare the performance of these models, and also try out different values for $L$. \n",
    "\n",
    "Let's look at the two architectures.\n",
    "\n",
    "### 3.1 - 2-layer neural network\n",
    "\n",
    "<img src=\"images/2layerNN_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "<caption><center> <u>Figure 2</u>: 2-layer neural network. <br> The model can be summarized as: ***INPUT -> LINEAR -> RELU -> LINEAR -> SIGMOID -> OUTPUT***. </center></caption>\n",
    "\n",
    "<u>Detailed Architecture of figure 2</u>:\n",
    "- The input is a (64,64,3) image which is flattened to a vector of size $(12288,1)$. \n",
    "- The corresponding vector: $[x_0,x_1,...,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ of size $(n^{[1]}, 12288)$.\n",
    "- You then add a bias term and take its relu to get the following vector: $[a_0^{[1]}, a_1^{[1]},..., a_{n^{[1]}-1}^{[1]}]^T$.\n",
    "- You then repeat the same process.\n",
    "- You multiply the resulting vector by $W^{[2]}$ and add your intercept (bias). \n",
    "- Finally, you take the sigmoid of the result. If it is greater than 0.5, you classify it to be a cat.\n",
    "\n",
    "### 3.2 - L-layer deep neural network\n",
    "\n",
    "It is hard to represent an L-layer deep neural network with the above representation. However, here is a simplified network representation:\n",
    "\n",
    "<img src=\"images/LlayerNN_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "<caption><center> <u>Figure 3</u>: L-layer neural network. <br> The model can be summarized as: ***[LINEAR -> RELU] $\\times$ (L-1) -> LINEAR -> SIGMOID***</center></caption>\n",
    "\n",
    "<u>Detailed Architecture of figure 3</u>:\n",
    "- The input is a (64,64,3) image which is flattened to a vector of size (12288,1).\n",
    "- The corresponding vector: $[x_0,x_1,...,x_{12287}]^T$ is then multiplied by the weight matrix $W^{[1]}$ and then you add the intercept $b^{[1]}$. The result is called the linear unit.\n",
    "- Next, you take the relu of the linear unit. This process could be repeated several times for each $(W^{[l]}, b^{[l]})$ depending on the model architecture.\n",
    "- Finally, you take the sigmoid of the final linear unit. If it is greater than 0.5, you classify it to be a cat.\n",
    "\n",
    "### 3.3 - General methodology\n",
    "\n",
    "As usual you will follow the Deep Learning methodology to build the model:\n",
    "    1. Initialize parameters / Define hyperparameters\n",
    "    2. Loop for num_iterations:\n",
    "        a. Forward propagation\n",
    "        b. Compute cost function\n",
    "        c. Backward propagation\n",
    "        d. Update parameters (using parameters, and grads from backprop) \n",
    "    4. Use trained parameters to predict labels\n",
    "\n",
    "Let's now implement those two models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Two-layer neural network\n",
    "\n",
    "**Question**:  Use the helper functions you have implemented in the previous assignment to build a 2-layer neural network with the following structure: *LINEAR -> RELU -> LINEAR -> SIGMOID*. The functions you may need and their inputs are:\n",
    "```python\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    ...\n",
    "    return parameters \n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    ...\n",
    "    return A, cache\n",
    "def compute_cost(AL, Y):\n",
    "    ...\n",
    "    return cost\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    ...\n",
    "    return dA_prev, dW, db\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    ...\n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS DEFINING THE MODEL ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7\n",
    "n_y = 1\n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: two_layer_model\n",
    "\n",
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    ### START CODE HERE ### (≈ 1 line of code)\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(A2, Y)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (approx. 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to train your parameters. See if your model runs. The cost should be decreasing. It may take up to 5 minutes to run 2500 iterations. Check if the \"Cost after iteration 0\" matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6930497356599888\n",
      "Cost after iteration 100: 0.6464320953428849\n",
      "Cost after iteration 200: 0.6325140647912677\n",
      "Cost after iteration 300: 0.6015024920354665\n",
      "Cost after iteration 400: 0.5601966311605747\n",
      "Cost after iteration 500: 0.515830477276473\n",
      "Cost after iteration 600: 0.4754901313943325\n",
      "Cost after iteration 700: 0.4339163151225749\n",
      "Cost after iteration 800: 0.4007977536203887\n",
      "Cost after iteration 900: 0.3580705011323798\n",
      "Cost after iteration 1000: 0.3394281538366412\n",
      "Cost after iteration 1100: 0.3052753636196264\n",
      "Cost after iteration 1200: 0.27491377282130164\n",
      "Cost after iteration 1300: 0.24681768210614846\n",
      "Cost after iteration 1400: 0.19850735037466116\n",
      "Cost after iteration 1500: 0.1744831811255664\n",
      "Cost after iteration 1600: 0.17080762978096148\n",
      "Cost after iteration 1700: 0.11306524562164734\n",
      "Cost after iteration 1800: 0.09629426845937152\n",
      "Cost after iteration 1900: 0.08342617959726863\n",
      "Cost after iteration 2000: 0.07439078704319081\n",
      "Cost after iteration 2100: 0.0663074813226793\n",
      "Cost after iteration 2200: 0.0591932950103817\n",
      "Cost after iteration 2300: 0.053361403485605585\n",
      "Cost after iteration 2400: 0.04855478562877016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y), num_iterations = 2500, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.6930497356599888 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 100**</td>\n",
    "        <td> 0.6464320953428849 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.048554785628770206 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good thing you built a vectorized implementation! Otherwise it might have taken 10 times longer to train this.\n",
    "\n",
    "Now, you can use the trained parameters to classify images from the dataset. To see your predictions on the training and test sets, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Accuracy**</td>\n",
    "        <td> 1.0 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "predictions_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Accuracy**</td>\n",
    "        <td> 0.72 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You may notice that running the model on fewer iterations (say 1500) gives better accuracy on the test set. This is called \"early stopping\" and we will talk about it in the next course. Early stopping is a way to prevent overfitting. \n",
    "\n",
    "Congratulations! It seems that your 2-layer neural network has better performance (72%) than the logistic regression implementation (70%, assignment week 2). Let's see if you can do even better with an $L$-layer model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - L-layer Neural Network\n",
    "\n",
    "**Question**: Use the helper functions you have implemented previously to build an $L$-layer neural network with the following structure: *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. The functions you may need and their inputs are:\n",
    "```python\n",
    "def initialize_parameters_deep(layers_dims):\n",
    "    ...\n",
    "    return parameters \n",
    "def L_model_forward(X, parameters):\n",
    "    ...\n",
    "    return AL, caches\n",
    "def compute_cost(AL, Y):\n",
    "    ...\n",
    "    return cost\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    ...\n",
    "    return grads\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    ...\n",
    "    return parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS ###\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  4-layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: L_layer_model\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "    \n",
    "    # Parameters initialization. (≈ 1 line of code)\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "        #print('learning rate ', learning_rate, 'iteration ',i)\n",
    "        print('para ',parameters['W1'][0,0], 'iteration ',i)\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Compute cost.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        #print('cpst is ',cost)\n",
    "        ### END CODE HERE ###\n",
    "        #print('cache length is: ', len(caches))\n",
    "    \n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        ### END CODE HERE ###\n",
    " \n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "                \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now train the model as a 4-layer neural network. \n",
    "\n",
    "Run the cell below to train your model. The cost should decrease on every iteration. It may take up to 5 minutes to run 2500 iterations. Check if the \"Cost after iteration 0\" matches the expected output below, if not click on the square (⬛) on the upper bar of the notebook to stop the cell and try to find your error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.014653378640123331 iteration  0\n",
      "Cost after iteration 0: 0.771749\n",
      "para  0.014486644096030845 iteration  1\n",
      "para  0.014487774551042656 iteration  2\n",
      "para  0.014487489289392006 iteration  3\n",
      "para  0.014487436753285473 iteration  4\n",
      "para  0.014487384409848415 iteration  5\n",
      "para  0.014487140393926245 iteration  6\n",
      "para  0.014486896701844372 iteration  7\n",
      "para  0.014486628907120314 iteration  8\n",
      "para  0.014486661253364475 iteration  9\n",
      "para  0.014486529588618466 iteration  10\n",
      "para  0.014486398229129172 iteration  11\n",
      "para  0.014486233726504084 iteration  12\n",
      "para  0.014486266463657405 iteration  13\n",
      "para  0.014486102623308192 iteration  14\n",
      "para  0.014485991924749817 iteration  15\n",
      "para  0.014485881531293395 iteration  16\n",
      "para  0.014485588584763816 iteration  17\n",
      "para  0.014485478882961688 iteration  18\n",
      "para  0.014485264209612382 iteration  19\n",
      "para  0.01448521248273748 iteration  20\n",
      "para  0.014485160802048294 iteration  21\n",
      "para  0.014485109060395915 iteration  22\n",
      "para  0.014485057502181268 iteration  23\n",
      "para  0.014485005883558489 iteration  24\n",
      "para  0.014484595884493029 iteration  25\n",
      "para  0.014484544362600337 iteration  26\n",
      "para  0.014484492787896845 iteration  27\n",
      "para  0.014484441341408253 iteration  28\n",
      "para  0.014484352670782179 iteration  29\n",
      "para  0.014484264097484649 iteration  30\n",
      "para  0.014484128005416725 iteration  31\n",
      "para  0.014484039613230096 iteration  32\n",
      "para  0.014483903807116763 iteration  33\n",
      "para  0.014483768068806658 iteration  34\n",
      "para  0.014483465788922286 iteration  35\n",
      "para  0.014483441892152766 iteration  36\n",
      "para  0.014483343267900193 iteration  37\n",
      "para  0.014483244737936747 iteration  38\n",
      "para  0.014483146312880052 iteration  39\n",
      "para  0.014482886202953777 iteration  40\n",
      "para  0.014482578460547513 iteration  41\n",
      "para  0.014482480251867247 iteration  42\n",
      "para  0.014482019837590586 iteration  43\n",
      "para  0.014481969007008518 iteration  44\n",
      "para  0.014481736548980072 iteration  45\n",
      "para  0.014481638594629406 iteration  46\n",
      "para  0.014482380108333023 iteration  47\n",
      "para  0.014482329467012207 iteration  48\n",
      "para  0.014482097831974329 iteration  49\n",
      "para  0.014482632095878321 iteration  50\n",
      "para  0.014482581563236733 iteration  51\n",
      "para  0.014482906055229606 iteration  52\n",
      "para  0.014483439824501163 iteration  53\n",
      "para  0.014483810671038915 iteration  54\n",
      "para  0.014483975723776568 iteration  55\n",
      "para  0.014484169692105562 iteration  56\n",
      "para  0.014484540955344924 iteration  57\n",
      "para  0.014484865120741123 iteration  58\n",
      "para  0.014485190526881499 iteration  59\n",
      "para  0.014485515913358907 iteration  60\n",
      "para  0.014486339888880699 iteration  61\n",
      "para  0.014486663076544455 iteration  62\n",
      "para  0.014487489979072956 iteration  63\n",
      "para  0.01448781617581465 iteration  64\n",
      "para  0.014488436268341214 iteration  65\n",
      "para  0.014488761330554614 iteration  66\n",
      "para  0.014489395710143313 iteration  67\n",
      "para  0.01448998051583139 iteration  68\n",
      "para  0.014490564914077346 iteration  69\n",
      "para  0.014491196953231573 iteration  70\n",
      "para  0.014491781239886693 iteration  71\n",
      "para  0.014492416078962813 iteration  72\n",
      "para  0.014493093232027809 iteration  73\n",
      "para  0.014493678335893784 iteration  74\n",
      "para  0.014494047822133269 iteration  75\n",
      "para  0.014494416391907947 iteration  76\n",
      "para  0.014495141836325125 iteration  77\n",
      "para  0.014495510670562485 iteration  78\n",
      "para  0.014496237330538933 iteration  79\n",
      "para  0.014496607565297682 iteration  80\n",
      "para  0.01449697737024188 iteration  81\n",
      "para  0.014497348112681349 iteration  82\n",
      "para  0.01449802601626446 iteration  83\n",
      "para  0.014498777321007001 iteration  84\n",
      "para  0.014499526825309625 iteration  85\n",
      "para  0.014500162331733143 iteration  86\n",
      "para  0.014501076697894286 iteration  87\n",
      "para  0.014502295181682043 iteration  88\n",
      "para  0.014503306019234675 iteration  89\n",
      "para  0.014504263855129955 iteration  90\n",
      "para  0.0145055310092146 iteration  91\n",
      "para  0.014506441496820094 iteration  92\n",
      "para  0.014507403510846447 iteration  93\n",
      "para  0.014508007017254918 iteration  94\n",
      "para  0.01450918665729052 iteration  95\n",
      "para  0.014510358259203349 iteration  96\n",
      "para  0.014511312561731306 iteration  97\n",
      "para  0.014512482727999602 iteration  98\n",
      "para  0.014513085929245327 iteration  99\n",
      "para  0.01451425735178264 iteration  100\n",
      "Cost after iteration 100: 0.672053\n",
      "para  0.014515423274712695 iteration  101\n",
      "para  0.01451659792442369 iteration  102\n",
      "para  0.01451776442980538 iteration  103\n",
      "para  0.01451836555750154 iteration  104\n",
      "para  0.01451953195595108 iteration  105\n",
      "para  0.01452069713475149 iteration  106\n",
      "para  0.014521866927286901 iteration  107\n",
      "para  0.014523030681103426 iteration  108\n",
      "para  0.014523589939525263 iteration  109\n",
      "para  0.01452475021634876 iteration  110\n",
      "para  0.014525926720819173 iteration  111\n",
      "para  0.014527093526105487 iteration  112\n",
      "para  0.014528536817251995 iteration  113\n",
      "para  0.014529726816588312 iteration  114\n",
      "para  0.014531168000532004 iteration  115\n",
      "para  0.014531284409018647 iteration  116\n",
      "para  0.014534442689212931 iteration  117\n",
      "para  0.014534800269368169 iteration  118\n",
      "para  0.01453556248447827 iteration  119\n",
      "para  0.014535877797963722 iteration  120\n",
      "para  0.014539201639250264 iteration  121\n",
      "para  0.014539319724920334 iteration  122\n",
      "para  0.014539621026116827 iteration  123\n",
      "para  0.014542540870052861 iteration  124\n",
      "para  0.014542932818414428 iteration  125\n",
      "para  0.01454591845475387 iteration  126\n",
      "para  0.014548660714638634 iteration  127\n",
      "para  0.01454847532591785 iteration  128\n",
      "para  0.014550987200891265 iteration  129\n",
      "para  0.014554229776675311 iteration  130\n",
      "para  0.01455422489524025 iteration  131\n",
      "para  0.01455653781248767 iteration  132\n",
      "para  0.014556838052855422 iteration  133\n",
      "para  0.014559531518095721 iteration  134\n",
      "para  0.014562766637989461 iteration  135\n",
      "para  0.014565000187005867 iteration  136\n",
      "para  0.014565724761158817 iteration  137\n",
      "para  0.014565823612876064 iteration  138\n",
      "para  0.014568732950167772 iteration  139\n",
      "para  0.014571720184923736 iteration  140\n",
      "para  0.014571966214299417 iteration  141\n",
      "para  0.014572067685322427 iteration  142\n",
      "para  0.014575546800340634 iteration  143\n",
      "para  0.014575924671773157 iteration  144\n",
      "para  0.014576024749854002 iteration  145\n",
      "para  0.01457915039386699 iteration  146\n",
      "para  0.014579280806560325 iteration  147\n",
      "para  0.01457938323548563 iteration  148\n",
      "para  0.014581893116947242 iteration  149\n",
      "para  0.014582321100235874 iteration  150\n",
      "para  0.014582413364709272 iteration  151\n",
      "para  0.014584645264494824 iteration  152\n",
      "para  0.01458749297999823 iteration  153\n",
      "para  0.014588719681756542 iteration  154\n",
      "para  0.014587850838173513 iteration  155\n",
      "para  0.014587450773107075 iteration  156\n",
      "para  0.014588891429672306 iteration  157\n",
      "para  0.01458943579149459 iteration  158\n",
      "para  0.01458952877988381 iteration  159\n",
      "para  0.014591961624221272 iteration  160\n",
      "para  0.014594797969053294 iteration  161\n",
      "para  0.014597247381669308 iteration  162\n",
      "para  0.014599190878214803 iteration  163\n",
      "para  0.014599321595479034 iteration  164\n",
      "para  0.01459920429795371 iteration  165\n",
      "para  0.014600644935631847 iteration  166\n",
      "para  0.014600421401099812 iteration  167\n",
      "para  0.01460029462251043 iteration  168\n",
      "para  0.014600373137036052 iteration  169\n",
      "para  0.01460049562025419 iteration  170\n",
      "para  0.014603158602499132 iteration  171\n",
      "para  0.014603710181068137 iteration  172\n",
      "para  0.014603367827608299 iteration  173\n",
      "para  0.014604816965460368 iteration  174\n",
      "para  0.014605420760468427 iteration  175\n",
      "para  0.014608073281062648 iteration  176\n",
      "para  0.014608296813663017 iteration  177\n",
      "para  0.014608162067042645 iteration  178\n",
      "para  0.014610843411350298 iteration  179\n",
      "para  0.014611927296937907 iteration  180\n",
      "para  0.014611797701344343 iteration  181\n",
      "para  0.014612749283011399 iteration  182\n",
      "para  0.014613494112819826 iteration  183\n",
      "para  0.014613354103362008 iteration  184\n",
      "para  0.014616001435570018 iteration  185\n",
      "para  0.01461620274449386 iteration  186\n",
      "para  0.014616069787319904 iteration  187\n",
      "para  0.014617022058176566 iteration  188\n",
      "para  0.014618025612539016 iteration  189\n",
      "para  0.01461758456569432 iteration  190\n",
      "para  0.014620887006772727 iteration  191\n",
      "para  0.014620902201711222 iteration  192\n",
      "para  0.014620458441685314 iteration  193\n",
      "para  0.014624215809606822 iteration  194\n",
      "para  0.014625167288804657 iteration  195\n",
      "para  0.014626849997976317 iteration  196\n",
      "para  0.014626028626684509 iteration  197\n",
      "para  0.014625583863157926 iteration  198\n",
      "para  0.014629331754786193 iteration  199\n",
      "para  0.014628618747381089 iteration  200\n",
      "Cost after iteration 200: 0.648263\n",
      "para  0.014629367186618454 iteration  201\n",
      "para  0.014629328645916822 iteration  202\n",
      "para  0.014629379497098288 iteration  203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.014633110794004377 iteration  204\n",
      "para  0.014629537112599504 iteration  205\n",
      "para  0.014628883150768875 iteration  206\n",
      "para  0.014629838219406905 iteration  207\n",
      "para  0.014630526921995452 iteration  208\n",
      "para  0.014629870972986765 iteration  209\n",
      "para  0.014633167430420393 iteration  210\n",
      "para  0.014631626667325103 iteration  211\n",
      "para  0.0146309727885716 iteration  212\n",
      "para  0.014633041145247256 iteration  213\n",
      "para  0.01463372059169146 iteration  214\n",
      "para  0.01463425088836008 iteration  215\n",
      "para  0.014637505268250858 iteration  216\n",
      "para  0.014635512720808895 iteration  217\n",
      "para  0.014634855573701904 iteration  218\n",
      "para  0.014636912510208225 iteration  219\n",
      "para  0.014634835198366909 iteration  220\n",
      "para  0.01463417308109495 iteration  221\n",
      "para  0.014636238735448052 iteration  222\n",
      "para  0.014636232602872556 iteration  223\n",
      "para  0.014635552280465584 iteration  224\n",
      "para  0.014637609759913668 iteration  225\n",
      "para  0.014636438037977506 iteration  226\n",
      "para  0.014635771640300329 iteration  227\n",
      "para  0.014637831397223034 iteration  228\n",
      "para  0.014636675303462843 iteration  229\n",
      "para  0.014636014470954363 iteration  230\n",
      "para  0.014638083353912618 iteration  231\n",
      "para  0.014636800363295416 iteration  232\n",
      "para  0.014636309133608381 iteration  233\n",
      "para  0.014639939278099012 iteration  234\n",
      "para  0.014639178201788079 iteration  235\n",
      "para  0.014640808432478345 iteration  236\n",
      "para  0.014638869622537114 iteration  237\n",
      "para  0.014639337851300161 iteration  238\n",
      "para  0.014641478476430554 iteration  239\n",
      "para  0.014641731035573443 iteration  240\n",
      "para  0.014642251966148927 iteration  241\n",
      "para  0.014643864460931678 iteration  242\n",
      "para  0.014645957811776885 iteration  243\n",
      "para  0.014646221571588496 iteration  244\n",
      "para  0.014649290786446195 iteration  245\n",
      "para  0.0146498524534527 iteration  246\n",
      "para  0.014646501823914969 iteration  247\n",
      "para  0.014650364389070436 iteration  248\n",
      "para  0.014647029546922905 iteration  249\n",
      "para  0.014648445974000281 iteration  250\n",
      "para  0.014649853207368318 iteration  251\n",
      "para  0.014646543245169216 iteration  252\n",
      "para  0.014649521725629208 iteration  253\n",
      "para  0.014650823334537722 iteration  254\n",
      "para  0.014650277088652026 iteration  255\n",
      "para  0.01464838651795197 iteration  256\n",
      "para  0.014650330867017702 iteration  257\n",
      "para  0.014648171948575536 iteration  258\n",
      "para  0.014649474472495237 iteration  259\n",
      "para  0.01465119078146064 iteration  260\n",
      "para  0.014649558440338505 iteration  261\n",
      "para  0.014651267561375745 iteration  262\n",
      "para  0.014652572646509567 iteration  263\n",
      "para  0.014649968011820617 iteration  264\n",
      "para  0.014652967836319088 iteration  265\n",
      "para  0.014651152402750698 iteration  266\n",
      "para  0.01465307063154678 iteration  267\n",
      "para  0.014649773464393435 iteration  268\n",
      "para  0.01465150338427311 iteration  269\n",
      "para  0.014653301004644475 iteration  270\n",
      "para  0.014650694970477713 iteration  271\n",
      "para  0.014653726514648167 iteration  272\n",
      "para  0.014655633063076427 iteration  273\n",
      "para  0.014653053568522265 iteration  274\n",
      "para  0.014655934124019037 iteration  275\n",
      "para  0.014656292765938135 iteration  276\n",
      "para  0.01465810438763231 iteration  277\n",
      "para  0.01465943802267528 iteration  278\n",
      "para  0.014656880392747198 iteration  279\n",
      "para  0.014660578984922434 iteration  280\n",
      "para  0.0146598351756065 iteration  281\n",
      "para  0.014657485940570971 iteration  282\n",
      "para  0.014659425162536691 iteration  283\n",
      "para  0.014656843754080159 iteration  284\n",
      "para  0.014660562045173917 iteration  285\n",
      "para  0.014662509809224625 iteration  286\n",
      "para  0.014659722319896446 iteration  287\n",
      "para  0.014662632809543722 iteration  288\n",
      "para  0.01466503109104619 iteration  289\n",
      "para  0.014661728025965657 iteration  290\n",
      "para  0.014664629626703177 iteration  291\n",
      "para  0.014666134863620573 iteration  292\n",
      "para  0.014663371430963617 iteration  293\n",
      "para  0.01466630495320972 iteration  294\n",
      "para  0.014668599332495097 iteration  295\n",
      "para  0.01466555985628683 iteration  296\n",
      "para  0.014667149620879541 iteration  297\n",
      "para  0.014669111454242224 iteration  298\n",
      "para  0.014666309039568861 iteration  299\n",
      "para  0.014669233703681468 iteration  300\n",
      "Cost after iteration 300: 0.611507\n",
      "para  0.014669510843950722 iteration  301\n",
      "para  0.014666713419150192 iteration  302\n",
      "para  0.014668303253513029 iteration  303\n",
      "para  0.01467028480933027 iteration  304\n",
      "para  0.01466747410130779 iteration  305\n",
      "para  0.014670399368502021 iteration  306\n",
      "para  0.014669355209014696 iteration  307\n",
      "para  0.014666646015766211 iteration  308\n",
      "para  0.01466803502760169 iteration  309\n",
      "para  0.014668669044733148 iteration  310\n",
      "para  0.01466885208290168 iteration  311\n",
      "para  0.014672495255002471 iteration  312\n",
      "para  0.014669597821434946 iteration  313\n",
      "para  0.014671187864824431 iteration  314\n",
      "para  0.014674219630032924 iteration  315\n",
      "para  0.014671657530444132 iteration  316\n",
      "para  0.014674610706151586 iteration  317\n",
      "para  0.014676589662609497 iteration  318\n",
      "para  0.014673844062634089 iteration  319\n",
      "para  0.014675215936385612 iteration  320\n",
      "para  0.014675750801770904 iteration  321\n",
      "para  0.014673118500655785 iteration  322\n",
      "para  0.014677130718989741 iteration  323\n",
      "para  0.014675753490343973 iteration  324\n",
      "para  0.014676677364820468 iteration  325\n",
      "para  0.014679400052371274 iteration  326\n",
      "para  0.014683241324349275 iteration  327\n",
      "para  0.014679338850220483 iteration  328\n",
      "para  0.014680104802419536 iteration  329\n",
      "para  0.01468232398715961 iteration  330\n",
      "para  0.014684857623470706 iteration  331\n",
      "para  0.014681419298598501 iteration  332\n",
      "para  0.014682865613270245 iteration  333\n",
      "para  0.014682384248531926 iteration  334\n",
      "para  0.014686074229318053 iteration  335\n",
      "para  0.014682954846931981 iteration  336\n",
      "para  0.014684874486316264 iteration  337\n",
      "para  0.014685687621407859 iteration  338\n",
      "para  0.014682677543788117 iteration  339\n",
      "para  0.014685834345850924 iteration  340\n",
      "para  0.014686679745974021 iteration  341\n",
      "para  0.014689637232163592 iteration  342\n",
      "para  0.01468987890580269 iteration  343\n",
      "para  0.0146917736461154 iteration  344\n",
      "para  0.014691943795178602 iteration  345\n",
      "para  0.014692006367462365 iteration  346\n",
      "para  0.014693913202663977 iteration  347\n",
      "para  0.014697796988504328 iteration  348\n",
      "para  0.014699311131618773 iteration  349\n",
      "para  0.014700785877893589 iteration  350\n",
      "para  0.014696148370972415 iteration  351\n",
      "para  0.014701660627292225 iteration  352\n",
      "para  0.01469614388024148 iteration  353\n",
      "para  0.014696856556107132 iteration  354\n",
      "para  0.014697834909937302 iteration  355\n",
      "para  0.01469394103426196 iteration  356\n",
      "para  0.014687797345295928 iteration  357\n",
      "para  0.014688415513461076 iteration  358\n",
      "para  0.014690182605575105 iteration  359\n",
      "para  0.014684124988362069 iteration  360\n",
      "para  0.014685972223125527 iteration  361\n",
      "para  0.01468844604231312 iteration  362\n",
      "para  0.014682738731559695 iteration  363\n",
      "para  0.014683186668607979 iteration  364\n",
      "para  0.014686539116547742 iteration  365\n",
      "para  0.014684011302245519 iteration  366\n",
      "para  0.014678496745456066 iteration  367\n",
      "para  0.014681811830585404 iteration  368\n",
      "para  0.014681535534720236 iteration  369\n",
      "para  0.014677122598220979 iteration  370\n",
      "para  0.014678685024243859 iteration  371\n",
      "para  0.014680830655936585 iteration  372\n",
      "para  0.014677261404077034 iteration  373\n",
      "para  0.01467926334850744 iteration  374\n",
      "para  0.014675452963253312 iteration  375\n",
      "para  0.014674933740412042 iteration  376\n",
      "para  0.014677775509047957 iteration  377\n",
      "para  0.01467474682059649 iteration  378\n",
      "para  0.014678143791732637 iteration  379\n",
      "para  0.014683301341631896 iteration  380\n",
      "para  0.01467986401174909 iteration  381\n",
      "para  0.014684923435747165 iteration  382\n",
      "para  0.014677084191385083 iteration  383\n",
      "para  0.014686954434078968 iteration  384\n",
      "para  0.014690270219717682 iteration  385\n",
      "para  0.014685006975015727 iteration  386\n",
      "para  0.014698743529031532 iteration  387\n",
      "para  0.014678628409317915 iteration  388\n",
      "para  0.014685213447757093 iteration  389\n",
      "para  0.014693667065268744 iteration  390\n",
      "para  0.014683246997106802 iteration  391\n",
      "para  0.014692464559963148 iteration  392\n",
      "para  0.014702466089020864 iteration  393\n",
      "para  0.014695785254637904 iteration  394\n",
      "para  0.014699497321970517 iteration  395\n",
      "para  0.014688338403106233 iteration  396\n",
      "para  0.014699566523164103 iteration  397\n",
      "para  0.014676617409268247 iteration  398\n",
      "para  0.014682335683127578 iteration  399\n",
      "para  0.014694686189326796 iteration  400\n",
      "Cost after iteration 400: 0.567047\n",
      "para  0.01470138308355985 iteration  401\n",
      "para  0.014684064558836404 iteration  402\n",
      "para  0.014696064132948009 iteration  403\n",
      "para  0.014696799969485547 iteration  404\n",
      "para  0.014706691290613243 iteration  405\n",
      "para  0.014695313442635433 iteration  406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.014707685869240372 iteration  407\n",
      "para  0.014689538580306739 iteration  408\n",
      "para  0.014696563467207907 iteration  409\n",
      "para  0.014708716173134821 iteration  410\n",
      "para  0.014703579030568098 iteration  411\n",
      "para  0.01470764620052035 iteration  412\n",
      "para  0.014695709635930186 iteration  413\n",
      "para  0.014711126386504528 iteration  414\n",
      "para  0.014680087654236057 iteration  415\n",
      "para  0.014686479010975384 iteration  416\n",
      "para  0.014697428007313693 iteration  417\n",
      "para  0.014709295641018362 iteration  418\n",
      "para  0.014684359271092514 iteration  419\n",
      "para  0.014693883263447706 iteration  420\n",
      "para  0.014706507516633152 iteration  421\n",
      "para  0.01468758212225153 iteration  422\n",
      "para  0.014696452620255146 iteration  423\n",
      "para  0.014705920545319108 iteration  424\n",
      "para  0.014704798232351164 iteration  425\n",
      "para  0.014709127236276206 iteration  426\n",
      "para  0.014705505736019416 iteration  427\n",
      "para  0.014707008446085194 iteration  428\n",
      "para  0.014707584292857791 iteration  429\n",
      "para  0.014688456705383176 iteration  430\n",
      "para  0.014702354961524952 iteration  431\n",
      "para  0.014700227325054094 iteration  432\n",
      "para  0.014711038605562249 iteration  433\n",
      "para  0.014690361930265221 iteration  434\n",
      "para  0.01470065881805721 iteration  435\n",
      "para  0.0147147604597141 iteration  436\n",
      "para  0.014684192492927996 iteration  437\n",
      "para  0.014689621877762368 iteration  438\n",
      "para  0.01470117773134643 iteration  439\n",
      "para  0.014714461010488303 iteration  440\n",
      "para  0.01468695025331917 iteration  441\n",
      "para  0.01469683889928344 iteration  442\n",
      "para  0.014714429269730163 iteration  443\n",
      "para  0.014700879435139806 iteration  444\n",
      "para  0.0147154283128153 iteration  445\n",
      "para  0.014734249265310355 iteration  446\n",
      "para  0.01468567747750844 iteration  447\n",
      "para  0.014696895291254213 iteration  448\n",
      "para  0.014708556395348096 iteration  449\n",
      "para  0.014720456803894437 iteration  450\n",
      "para  0.014708403476296667 iteration  451\n",
      "para  0.014716664930053426 iteration  452\n",
      "para  0.0147283685879095 iteration  453\n",
      "para  0.014721925800467947 iteration  454\n",
      "para  0.014732872199540767 iteration  455\n",
      "para  0.01471995561719212 iteration  456\n",
      "para  0.014734566678621233 iteration  457\n",
      "para  0.014729147260731096 iteration  458\n",
      "para  0.014730512493100817 iteration  459\n",
      "para  0.014741593801738239 iteration  460\n",
      "para  0.014713144865856096 iteration  461\n",
      "para  0.014723326857545632 iteration  462\n",
      "para  0.01474067981743334 iteration  463\n",
      "para  0.014720091525024001 iteration  464\n",
      "para  0.014738154715341404 iteration  465\n",
      "para  0.014719785329158146 iteration  466\n",
      "para  0.014729949476170024 iteration  467\n",
      "para  0.014744643822450691 iteration  468\n",
      "para  0.01474871771778 iteration  469\n",
      "para  0.014736710196787529 iteration  470\n",
      "para  0.014752245584107192 iteration  471\n",
      "para  0.014718319878725666 iteration  472\n",
      "para  0.014726447852673366 iteration  473\n",
      "para  0.01473986634942065 iteration  474\n",
      "para  0.01475160155560763 iteration  475\n",
      "para  0.014731769334890102 iteration  476\n",
      "para  0.014744711342680197 iteration  477\n",
      "para  0.014763130401152598 iteration  478\n",
      "para  0.014745100938302889 iteration  479\n",
      "para  0.014760293414890387 iteration  480\n",
      "para  0.014771173188005431 iteration  481\n",
      "para  0.014758004542234637 iteration  482\n",
      "para  0.01477778483556594 iteration  483\n",
      "para  0.014745054510298285 iteration  484\n",
      "para  0.014761241556133318 iteration  485\n",
      "para  0.014782901787024207 iteration  486\n",
      "para  0.014741640592406962 iteration  487\n",
      "para  0.01475880261512132 iteration  488\n",
      "para  0.014775195841312315 iteration  489\n",
      "para  0.01479542804438777 iteration  490\n",
      "para  0.014750000080909832 iteration  491\n",
      "para  0.01476192165324523 iteration  492\n",
      "para  0.01478110759168745 iteration  493\n",
      "para  0.014795561639856502 iteration  494\n",
      "para  0.014766746649061979 iteration  495\n",
      "para  0.014787562584976028 iteration  496\n",
      "para  0.014786789497470493 iteration  497\n",
      "para  0.014805880777428986 iteration  498\n",
      "para  0.01481577832378513 iteration  499\n",
      "para  0.014790883656849683 iteration  500\n",
      "Cost after iteration 500: 0.540138\n",
      "para  0.014814185189925175 iteration  501\n",
      "para  0.014782214035455429 iteration  502\n",
      "para  0.014797343181090801 iteration  503\n",
      "para  0.014818587252720054 iteration  504\n",
      "para  0.014783194533065104 iteration  505\n",
      "para  0.014803054164971399 iteration  506\n",
      "para  0.014776892785643484 iteration  507\n",
      "para  0.014788198573346614 iteration  508\n",
      "para  0.014804985639191196 iteration  509\n",
      "para  0.01480576523094813 iteration  510\n",
      "para  0.014814033572764595 iteration  511\n",
      "para  0.014808873405515097 iteration  512\n",
      "para  0.014828348154762468 iteration  513\n",
      "para  0.014787233923083168 iteration  514\n",
      "para  0.014799472333156392 iteration  515\n",
      "para  0.014819789080741243 iteration  516\n",
      "para  0.014818366113130295 iteration  517\n",
      "para  0.01482906656680885 iteration  518\n",
      "para  0.014817767051892429 iteration  519\n",
      "para  0.014839616587634266 iteration  520\n",
      "para  0.014805710422399447 iteration  521\n",
      "para  0.014820145945248322 iteration  522\n",
      "para  0.01484050002028196 iteration  523\n",
      "para  0.014822401486687658 iteration  524\n",
      "para  0.014842683695213084 iteration  525\n",
      "para  0.014821493456092679 iteration  526\n",
      "para  0.014842779074291662 iteration  527\n",
      "para  0.014860084378060476 iteration  528\n",
      "para  0.01480517334486666 iteration  529\n",
      "para  0.014831154553748798 iteration  530\n",
      "para  0.014809883521562076 iteration  531\n",
      "para  0.014830055902004122 iteration  532\n",
      "para  0.014853895736875043 iteration  533\n",
      "para  0.014814012677868924 iteration  534\n",
      "para  0.014838847835699413 iteration  535\n",
      "para  0.01482136183751139 iteration  536\n",
      "para  0.014843471561903968 iteration  537\n",
      "para  0.014843789451241214 iteration  538\n",
      "para  0.014861885464342629 iteration  539\n",
      "para  0.014841539336298958 iteration  540\n",
      "para  0.01486523708195139 iteration  541\n",
      "para  0.014841702042999488 iteration  542\n",
      "para  0.014868626174253653 iteration  543\n",
      "para  0.014836406782158302 iteration  544\n",
      "para  0.014861864840961803 iteration  545\n",
      "para  0.014864550479309542 iteration  546\n",
      "para  0.014876431177186577 iteration  547\n",
      "para  0.014876057913607386 iteration  548\n",
      "para  0.014899134886687376 iteration  549\n",
      "para  0.01484460221752665 iteration  550\n",
      "para  0.014862109450873583 iteration  551\n",
      "para  0.01489028401799269 iteration  552\n",
      "para  0.01487259220260763 iteration  553\n",
      "para  0.014891371649608649 iteration  554\n",
      "para  0.014870255761065357 iteration  555\n",
      "para  0.014897577235922499 iteration  556\n",
      "para  0.014899899428844687 iteration  557\n",
      "para  0.014879985937809105 iteration  558\n",
      "para  0.014898737111086404 iteration  559\n",
      "para  0.014869112658460382 iteration  560\n",
      "para  0.014894657974908874 iteration  561\n",
      "para  0.014918963182762424 iteration  562\n",
      "para  0.014830680966336735 iteration  563\n",
      "para  0.014845791296249779 iteration  564\n",
      "para  0.014870160074264418 iteration  565\n",
      "para  0.014885132945205309 iteration  566\n",
      "para  0.014907249672493721 iteration  567\n",
      "para  0.0149144769475149 iteration  568\n",
      "para  0.014899930064082557 iteration  569\n",
      "para  0.014922286292888177 iteration  570\n",
      "para  0.014881467916591014 iteration  571\n",
      "para  0.01490745546331685 iteration  572\n",
      "para  0.014930912779909796 iteration  573\n",
      "para  0.014901828456891131 iteration  574\n",
      "para  0.01492987344647448 iteration  575\n",
      "para  0.014883740046124928 iteration  576\n",
      "para  0.014909267511687606 iteration  577\n",
      "para  0.014923598631811108 iteration  578\n",
      "para  0.014892159785655123 iteration  579\n",
      "para  0.01491538713383522 iteration  580\n",
      "para  0.014892768953507194 iteration  581\n",
      "para  0.014920612822627544 iteration  582\n",
      "para  0.014897813923029172 iteration  583\n",
      "para  0.014918069262695753 iteration  584\n",
      "para  0.01488443652443126 iteration  585\n",
      "para  0.014915156525689885 iteration  586\n",
      "para  0.014934431881347767 iteration  587\n",
      "para  0.014866974251077856 iteration  588\n",
      "para  0.014892610249772434 iteration  589\n",
      "para  0.014888066202314362 iteration  590\n",
      "para  0.01491323164181743 iteration  591\n",
      "para  0.014916190955105036 iteration  592\n",
      "para  0.014905501797597436 iteration  593\n",
      "para  0.014923687847173288 iteration  594\n",
      "para  0.014897582038382108 iteration  595\n",
      "para  0.014923905559946937 iteration  596\n",
      "para  0.014920066202807655 iteration  597\n",
      "para  0.01490246993281742 iteration  598\n",
      "para  0.014919530236257398 iteration  599\n",
      "para  0.014890525710377618 iteration  600\n",
      "Cost after iteration 600: 0.527930\n",
      "para  0.014923182866352353 iteration  601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.014915050449167473 iteration  602\n",
      "para  0.014925463851844317 iteration  603\n",
      "para  0.014896053754165823 iteration  604\n",
      "para  0.014917604351547084 iteration  605\n",
      "para  0.014889881796820506 iteration  606\n",
      "para  0.014917894885265934 iteration  607\n",
      "para  0.01492943189318841 iteration  608\n",
      "para  0.0148900003645515 iteration  609\n",
      "para  0.014917143396321586 iteration  610\n",
      "para  0.0148826788588239 iteration  611\n",
      "para  0.01491674086645329 iteration  612\n",
      "para  0.014939391465331511 iteration  613\n",
      "para  0.014849422058149585 iteration  614\n",
      "para  0.014873582445161751 iteration  615\n",
      "para  0.014898434620127663 iteration  616\n",
      "para  0.01490719560819572 iteration  617\n",
      "para  0.014934765031572952 iteration  618\n",
      "para  0.0149102347300508 iteration  619\n",
      "para  0.01493195814361618 iteration  620\n",
      "para  0.014881757339594572 iteration  621\n",
      "para  0.014913895218360833 iteration  622\n",
      "para  0.014938898875466698 iteration  623\n",
      "para  0.014907191204879938 iteration  624\n",
      "para  0.014941325453316903 iteration  625\n",
      "para  0.01488364520006484 iteration  626\n",
      "para  0.014910188691362267 iteration  627\n",
      "para  0.014934067995271912 iteration  628\n",
      "para  0.014926303477501507 iteration  629\n",
      "para  0.01494996959018311 iteration  630\n",
      "para  0.014906481295522536 iteration  631\n",
      "para  0.014936119349365016 iteration  632\n",
      "para  0.014946702250154084 iteration  633\n",
      "para  0.01490640952652907 iteration  634\n",
      "para  0.014931330131007095 iteration  635\n",
      "para  0.014899940240352127 iteration  636\n",
      "para  0.01493404236279164 iteration  637\n",
      "para  0.014958266033152352 iteration  638\n",
      "para  0.014860912158983733 iteration  639\n",
      "para  0.014884800007456428 iteration  640\n",
      "para  0.014906409377490815 iteration  641\n",
      "para  0.014912163612315368 iteration  642\n",
      "para  0.014948659302908255 iteration  643\n",
      "para  0.01497556898332209 iteration  644\n",
      "para  0.01486838241630455 iteration  645\n",
      "para  0.014892327882015026 iteration  646\n",
      "para  0.014915006497397836 iteration  647\n",
      "para  0.014914791207439097 iteration  648\n",
      "para  0.0149477850052602 iteration  649\n",
      "para  0.014969053525623067 iteration  650\n",
      "para  0.014892429229106463 iteration  651\n",
      "para  0.01492185529654476 iteration  652\n",
      "para  0.014946975484973129 iteration  653\n",
      "para  0.014929430199695257 iteration  654\n",
      "para  0.01495606721759891 iteration  655\n",
      "para  0.014941067730216508 iteration  656\n",
      "para  0.01496265734011071 iteration  657\n",
      "para  0.014912311475236341 iteration  658\n",
      "para  0.014942626953924261 iteration  659\n",
      "para  0.014968280181033217 iteration  660\n",
      "para  0.014929157367847388 iteration  661\n",
      "para  0.014964022160295973 iteration  662\n",
      "para  0.01492050122933885 iteration  663\n",
      "para  0.014945662297759135 iteration  664\n",
      "para  0.014927930780047848 iteration  665\n",
      "para  0.014953937469756928 iteration  666\n",
      "para  0.01494755812164548 iteration  667\n",
      "para  0.014963340940267777 iteration  668\n",
      "para  0.014925669760363088 iteration  669\n",
      "para  0.014956459825877805 iteration  670\n",
      "para  0.014943416395291858 iteration  671\n",
      "para  0.014974157267177372 iteration  672\n",
      "para  0.014932649953572326 iteration  673\n",
      "para  0.014965260137153 iteration  674\n",
      "para  0.014917773869412386 iteration  675\n",
      "para  0.014945556910847847 iteration  676\n",
      "para  0.014968005070699316 iteration  677\n",
      "para  0.014929517932952335 iteration  678\n",
      "para  0.014963632105789873 iteration  679\n",
      "para  0.01494297540863374 iteration  680\n",
      "para  0.014971690628499965 iteration  681\n",
      "para  0.014934247953645244 iteration  682\n",
      "para  0.014968086048449611 iteration  683\n",
      "para  0.014916115220934433 iteration  684\n",
      "para  0.014944824834580853 iteration  685\n",
      "para  0.014972084701618508 iteration  686\n",
      "para  0.014939910815484889 iteration  687\n",
      "para  0.01497076790764527 iteration  688\n",
      "para  0.014933416797366187 iteration  689\n",
      "para  0.014960085450878019 iteration  690\n",
      "para  0.01492836541178706 iteration  691\n",
      "para  0.014962116748071415 iteration  692\n",
      "para  0.014942080407556315 iteration  693\n",
      "para  0.014972726806679838 iteration  694\n",
      "para  0.014935198472576025 iteration  695\n",
      "para  0.014967631388527622 iteration  696\n",
      "para  0.01492060817447697 iteration  697\n",
      "para  0.014950484025323584 iteration  698\n",
      "para  0.014975068456695243 iteration  699\n",
      "para  0.014918502277034501 iteration  700\n",
      "Cost after iteration 700: 0.465477\n",
      "para  0.01495122989321279 iteration  701\n",
      "para  0.014956892498007367 iteration  702\n",
      "para  0.014977623015183825 iteration  703\n",
      "para  0.014941438377863417 iteration  704\n",
      "para  0.014974691704066265 iteration  705\n",
      "para  0.014951660822347827 iteration  706\n",
      "para  0.014985952902970213 iteration  707\n",
      "para  0.014953652698275846 iteration  708\n",
      "para  0.014990517325543956 iteration  709\n",
      "para  0.014916575115458217 iteration  710\n",
      "para  0.01494584087821861 iteration  711\n",
      "para  0.014968181029668317 iteration  712\n",
      "para  0.014952287953838957 iteration  713\n",
      "para  0.014987554464284666 iteration  714\n",
      "para  0.014933109032163314 iteration  715\n",
      "para  0.0149615871419804 iteration  716\n",
      "para  0.014985433460197822 iteration  717\n",
      "para  0.014933775370670971 iteration  718\n",
      "para  0.014959610519332124 iteration  719\n",
      "para  0.014968071098731136 iteration  720\n",
      "para  0.014983787061393866 iteration  721\n",
      "para  0.014952589740499154 iteration  722\n",
      "para  0.014988167091829494 iteration  723\n",
      "para  0.014948152447503363 iteration  724\n",
      "para  0.014980100249704819 iteration  725\n",
      "para  0.014945450808943848 iteration  726\n",
      "para  0.014976109838045449 iteration  727\n",
      "para  0.014977497159312663 iteration  728\n",
      "para  0.014977760238689481 iteration  729\n",
      "para  0.014964856003167703 iteration  730\n",
      "para  0.014986967497875876 iteration  731\n",
      "para  0.014928781725423614 iteration  732\n",
      "para  0.014959076386245362 iteration  733\n",
      "para  0.014964773762540894 iteration  734\n",
      "para  0.014978426198093161 iteration  735\n",
      "para  0.014961454139185273 iteration  736\n",
      "para  0.014999729054183649 iteration  737\n",
      "para  0.014916608827181302 iteration  738\n",
      "para  0.014948495677137937 iteration  739\n",
      "para  0.014989118566901098 iteration  740\n",
      "para  0.014921099430773854 iteration  741\n",
      "para  0.014948083147933222 iteration  742\n",
      "para  0.014963882803452254 iteration  743\n",
      "para  0.014983544169964592 iteration  744\n",
      "para  0.014961310623516685 iteration  745\n",
      "para  0.014999118006242868 iteration  746\n",
      "para  0.014918371708375563 iteration  747\n",
      "para  0.014952985075048764 iteration  748\n",
      "para  0.014991536285377723 iteration  749\n",
      "para  0.014936158958400399 iteration  750\n",
      "para  0.014967048057997036 iteration  751\n",
      "para  0.014972722998068117 iteration  752\n",
      "para  0.014994868934155959 iteration  753\n",
      "para  0.014955447409689552 iteration  754\n",
      "para  0.014994555703382964 iteration  755\n",
      "para  0.014955204027002025 iteration  756\n",
      "para  0.014993132542659058 iteration  757\n",
      "para  0.014968560363733688 iteration  758\n",
      "para  0.015002614664503923 iteration  759\n",
      "para  0.014919244697468593 iteration  760\n",
      "para  0.014952304111624086 iteration  761\n",
      "para  0.014971874449871534 iteration  762\n",
      "para  0.01496704466172573 iteration  763\n",
      "para  0.015003254638672133 iteration  764\n",
      "para  0.014916410877150694 iteration  765\n",
      "para  0.014951642108696999 iteration  766\n",
      "para  0.014988064427354057 iteration  767\n",
      "para  0.01493951601851871 iteration  768\n",
      "para  0.014970218537027947 iteration  769\n",
      "para  0.014984488923357244 iteration  770\n",
      "para  0.014981255885428639 iteration  771\n",
      "para  0.014994136348965481 iteration  772\n",
      "para  0.014972943187881966 iteration  773\n",
      "para  0.015004782988750819 iteration  774\n",
      "para  0.014947823080865461 iteration  775\n",
      "para  0.014977430459387655 iteration  776\n",
      "para  0.015012925353184749 iteration  777\n",
      "para  0.014947781998258369 iteration  778\n",
      "para  0.014978958369906745 iteration  779\n",
      "para  0.014982164852541066 iteration  780\n",
      "para  0.015007544524961837 iteration  781\n",
      "para  0.014969591082554554 iteration  782\n",
      "para  0.015001583217253315 iteration  783\n",
      "para  0.014988870630372046 iteration  784\n",
      "para  0.015014556499911529 iteration  785\n",
      "para  0.014971320434500661 iteration  786\n",
      "para  0.015015164125488789 iteration  787\n",
      "para  0.01497452807426872 iteration  788\n",
      "para  0.015015068703895892 iteration  789\n",
      "para  0.014985515234666508 iteration  790\n",
      "para  0.015023737984831797 iteration  791\n",
      "para  0.014942556547914406 iteration  792\n",
      "para  0.014975482569864305 iteration  793\n",
      "para  0.014999389866579116 iteration  794\n",
      "para  0.014986901955774888 iteration  795\n",
      "para  0.015022533756554947 iteration  796\n",
      "para  0.014957002225372286 iteration  797\n",
      "para  0.014990639834978805 iteration  798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.01500863038618222 iteration  799\n",
      "para  0.014993691305964943 iteration  800\n",
      "Cost after iteration 800: 0.369126\n",
      "para  0.015022481132578206 iteration  801\n",
      "para  0.014975946452628374 iteration  802\n",
      "para  0.015018456127253103 iteration  803\n",
      "para  0.01501427697213594 iteration  804\n",
      "para  0.015005237213815964 iteration  805\n",
      "para  0.015028632477993756 iteration  806\n",
      "para  0.014975016860265172 iteration  807\n",
      "para  0.015016179459723696 iteration  808\n",
      "para  0.015008488160114039 iteration  809\n",
      "para  0.015023783711814153 iteration  810\n",
      "para  0.015000836240465804 iteration  811\n",
      "para  0.015035934606079191 iteration  812\n",
      "para  0.014971037102629937 iteration  813\n",
      "para  0.015001058154972373 iteration  814\n",
      "para  0.01503273135221874 iteration  815\n",
      "para  0.014983693625321938 iteration  816\n",
      "para  0.01502789816494759 iteration  817\n",
      "para  0.01499433968573196 iteration  818\n",
      "para  0.015025482218509432 iteration  819\n",
      "para  0.01498512268027201 iteration  820\n",
      "para  0.015026843084655208 iteration  821\n",
      "para  0.015000195020636159 iteration  822\n",
      "para  0.01504319968392758 iteration  823\n",
      "para  0.014981949048660539 iteration  824\n",
      "para  0.015028880571762139 iteration  825\n",
      "para  0.014984350519724226 iteration  826\n",
      "para  0.015020735175300112 iteration  827\n",
      "para  0.01497532976589067 iteration  828\n",
      "para  0.01501132128941235 iteration  829\n",
      "para  0.01500082345654071 iteration  830\n",
      "para  0.015040357854501292 iteration  831\n",
      "para  0.014985244263874471 iteration  832\n",
      "para  0.01502548820722233 iteration  833\n",
      "para  0.014977990240005085 iteration  834\n",
      "para  0.015030773081148769 iteration  835\n",
      "para  0.014969256922740716 iteration  836\n",
      "para  0.014999887146253844 iteration  837\n",
      "para  0.015008619882334711 iteration  838\n",
      "para  0.015041615679111806 iteration  839\n",
      "para  0.014986838829678172 iteration  840\n",
      "para  0.01503811820274735 iteration  841\n",
      "para  0.014979321625311239 iteration  842\n",
      "para  0.015026347819351582 iteration  843\n",
      "para  0.015003085153933119 iteration  844\n",
      "para  0.015035892154251076 iteration  845\n",
      "para  0.014971171127683631 iteration  846\n",
      "para  0.015020825417649838 iteration  847\n",
      "para  0.014989044596664176 iteration  848\n",
      "para  0.015037457561655749 iteration  849\n",
      "para  0.014982601606672847 iteration  850\n",
      "para  0.015025503260376698 iteration  851\n",
      "para  0.015037112583732774 iteration  852\n",
      "para  0.015017031188515531 iteration  853\n",
      "para  0.015034917743598995 iteration  854\n",
      "para  0.015010081049691634 iteration  855\n",
      "para  0.015042656694055911 iteration  856\n",
      "para  0.014989099578644785 iteration  857\n",
      "para  0.015035202639772316 iteration  858\n",
      "para  0.015005175117957717 iteration  859\n",
      "para  0.015045796286040653 iteration  860\n",
      "para  0.014977800420012068 iteration  861\n",
      "para  0.015016855637059689 iteration  862\n",
      "para  0.015040088264519028 iteration  863\n",
      "para  0.014994847134489484 iteration  864\n",
      "para  0.015039975118682068 iteration  865\n",
      "para  0.014993011600306036 iteration  866\n",
      "para  0.015042017421252305 iteration  867\n",
      "para  0.015019202295917206 iteration  868\n",
      "para  0.015052491900784476 iteration  869\n",
      "para  0.014987779420847048 iteration  870\n",
      "para  0.015034494217736871 iteration  871\n",
      "para  0.015005055490662795 iteration  872\n",
      "para  0.015045110628292264 iteration  873\n",
      "para  0.015000057724860346 iteration  874\n",
      "para  0.015050772541224394 iteration  875\n",
      "para  0.015009553852278928 iteration  876\n",
      "para  0.015062949284530955 iteration  877\n",
      "para  0.015002786644640423 iteration  878\n",
      "para  0.015057071723035678 iteration  879\n",
      "para  0.015007678245074254 iteration  880\n",
      "para  0.015058732285641216 iteration  881\n",
      "para  0.015028120368719708 iteration  882\n",
      "para  0.015079168709419633 iteration  883\n",
      "para  0.015028515377278461 iteration  884\n",
      "para  0.015083086647905579 iteration  885\n",
      "para  0.015004704641556201 iteration  886\n",
      "para  0.01505544926458604 iteration  887\n",
      "para  0.01502356386872285 iteration  888\n",
      "para  0.015071870317221361 iteration  889\n",
      "para  0.015035629994474654 iteration  890\n",
      "para  0.01508287154039526 iteration  891\n",
      "para  0.015042417835878013 iteration  892\n",
      "para  0.015093524339806295 iteration  893\n",
      "para  0.015019429059702534 iteration  894\n",
      "para  0.015067586930625506 iteration  895\n",
      "para  0.015049338627970804 iteration  896\n",
      "para  0.015087294094918293 iteration  897\n",
      "para  0.015046182964460466 iteration  898\n",
      "para  0.015092924189617827 iteration  899\n",
      "para  0.01502003321122432 iteration  900\n",
      "Cost after iteration 900: 0.391747\n",
      "para  0.015070822528017547 iteration  901\n",
      "para  0.015069901325732793 iteration  902\n",
      "para  0.015097627808304764 iteration  903\n",
      "para  0.015056289048883634 iteration  904\n",
      "para  0.01511256698568863 iteration  905\n",
      "para  0.01506151022880475 iteration  906\n",
      "para  0.015109465393620116 iteration  907\n",
      "para  0.01505507450715891 iteration  908\n",
      "para  0.015108821787921011 iteration  909\n",
      "para  0.015088699436141011 iteration  910\n",
      "para  0.015133229238715556 iteration  911\n",
      "para  0.015066843817040407 iteration  912\n",
      "para  0.01511877450208066 iteration  913\n",
      "para  0.015075917535828294 iteration  914\n",
      "para  0.015110166111727632 iteration  915\n",
      "para  0.015070306542304375 iteration  916\n",
      "para  0.015117876588135805 iteration  917\n",
      "para  0.015074783170980401 iteration  918\n",
      "para  0.015121611513416117 iteration  919\n",
      "para  0.01507971065659409 iteration  920\n",
      "para  0.015133847389113136 iteration  921\n",
      "para  0.015085417441424784 iteration  922\n",
      "para  0.015132953410617038 iteration  923\n",
      "para  0.01507641407483041 iteration  924\n",
      "para  0.015131299384272216 iteration  925\n",
      "para  0.015105278813680068 iteration  926\n",
      "para  0.015154969942424348 iteration  927\n",
      "para  0.015087025041052922 iteration  928\n",
      "para  0.015141954647780408 iteration  929\n",
      "para  0.015129153173641618 iteration  930\n",
      "para  0.015161092226925051 iteration  931\n",
      "para  0.015103658292885248 iteration  932\n",
      "para  0.015158286125686116 iteration  933\n",
      "para  0.015104515740736204 iteration  934\n",
      "para  0.015158430344617923 iteration  935\n",
      "para  0.015104903711696207 iteration  936\n",
      "para  0.015158724074172139 iteration  937\n",
      "para  0.015135523771402237 iteration  938\n",
      "para  0.015184478342230238 iteration  939\n",
      "para  0.015115779706341167 iteration  940\n",
      "para  0.015169248462162829 iteration  941\n",
      "para  0.015133928657625802 iteration  942\n",
      "para  0.01517164442773763 iteration  943\n",
      "para  0.015121053463932365 iteration  944\n",
      "para  0.015173583502462498 iteration  945\n",
      "para  0.015146077778401714 iteration  946\n",
      "para  0.015195296173925272 iteration  947\n",
      "para  0.015125957152549318 iteration  948\n",
      "para  0.015181358617816786 iteration  949\n",
      "para  0.01516707023015061 iteration  950\n",
      "para  0.015204069663871979 iteration  951\n",
      "para  0.015148095079578743 iteration  952\n",
      "para  0.01520601885281679 iteration  953\n",
      "para  0.01515465050420482 iteration  954\n",
      "para  0.015206376482135143 iteration  955\n",
      "para  0.015151578211445296 iteration  956\n",
      "para  0.01520842521721556 iteration  957\n",
      "para  0.015177982448623105 iteration  958\n",
      "para  0.015224799890793221 iteration  959\n",
      "para  0.015168492774374863 iteration  960\n",
      "para  0.015220602096290493 iteration  961\n",
      "para  0.015198245330787714 iteration  962\n",
      "para  0.015251013064173658 iteration  963\n",
      "para  0.015182549917973418 iteration  964\n",
      "para  0.015240835406549077 iteration  965\n",
      "para  0.01518851647503731 iteration  966\n",
      "para  0.015239599528543002 iteration  967\n",
      "para  0.015178321403051564 iteration  968\n",
      "para  0.01523360203666975 iteration  969\n",
      "para  0.015219095546829852 iteration  970\n",
      "para  0.015262417304494957 iteration  971\n",
      "para  0.015197400548352136 iteration  972\n",
      "para  0.015256170307820048 iteration  973\n",
      "para  0.015209425646051962 iteration  974\n",
      "para  0.01525169830917291 iteration  975\n",
      "para  0.015205183097007935 iteration  976\n",
      "para  0.015256069987264125 iteration  977\n",
      "para  0.01522850998814706 iteration  978\n",
      "para  0.015277017273936044 iteration  979\n",
      "para  0.015218612448044054 iteration  980\n",
      "para  0.015273771269948862 iteration  981\n",
      "para  0.015236218932267382 iteration  982\n",
      "para  0.015290250697798347 iteration  983\n",
      "para  0.015228272053554214 iteration  984\n",
      "para  0.015280402422326827 iteration  985\n",
      "para  0.01526322170666992 iteration  986\n",
      "para  0.015299973777589213 iteration  987\n",
      "para  0.015246364603599735 iteration  988\n",
      "para  0.01529395695529386 iteration  989\n",
      "para  0.015262045328044068 iteration  990\n",
      "para  0.015305842731062655 iteration  991\n",
      "para  0.015247487174940575 iteration  992\n",
      "para  0.015294437070439749 iteration  993\n",
      "para  0.015272830120932434 iteration  994\n",
      "para  0.015316168595950032 iteration  995\n",
      "para  0.015246158035078741 iteration  996\n",
      "para  0.015296279847460388 iteration  997\n",
      "para  0.0152681056652421 iteration  998\n",
      "para  0.015311949001008986 iteration  999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.015250715757964132 iteration  1000\n",
      "Cost after iteration 1000: 0.315187\n",
      "para  0.015299135106600976 iteration  1001\n",
      "para  0.015270481807548426 iteration  1002\n",
      "para  0.015311558997759949 iteration  1003\n",
      "para  0.015250107838377014 iteration  1004\n",
      "para  0.01530292520386279 iteration  1005\n",
      "para  0.015271841284303367 iteration  1006\n",
      "para  0.0153132969547014 iteration  1007\n",
      "para  0.015257837966736458 iteration  1008\n",
      "para  0.01530419813601615 iteration  1009\n",
      "para  0.015282057648302755 iteration  1010\n",
      "para  0.01531654602917258 iteration  1011\n",
      "para  0.015274785129136865 iteration  1012\n",
      "para  0.015313982502613495 iteration  1013\n",
      "para  0.015281409010167953 iteration  1014\n",
      "para  0.015320903286118464 iteration  1015\n",
      "para  0.015274980144616188 iteration  1016\n",
      "para  0.015317256064050152 iteration  1017\n",
      "para  0.015272489883945573 iteration  1018\n",
      "para  0.015315460618408858 iteration  1019\n",
      "para  0.015284231630772077 iteration  1020\n",
      "para  0.015317042646125888 iteration  1021\n",
      "para  0.01527887081140705 iteration  1022\n",
      "para  0.015319636314766566 iteration  1023\n",
      "para  0.015279896268594446 iteration  1024\n",
      "para  0.015321660118816523 iteration  1025\n",
      "para  0.015256007172667337 iteration  1026\n",
      "para  0.015315594466968742 iteration  1027\n",
      "para  0.015282128925596454 iteration  1028\n",
      "para  0.015329344184884575 iteration  1029\n",
      "para  0.01528200551766238 iteration  1030\n",
      "para  0.015322418563983652 iteration  1031\n",
      "para  0.015295673561670203 iteration  1032\n",
      "para  0.01533210403689976 iteration  1033\n",
      "para  0.015277345986028599 iteration  1034\n",
      "para  0.015321015367057876 iteration  1035\n",
      "para  0.015305675532219714 iteration  1036\n",
      "para  0.015341731365612753 iteration  1037\n",
      "para  0.01528258341371642 iteration  1038\n",
      "para  0.01532992878233975 iteration  1039\n",
      "para  0.015318177455082037 iteration  1040\n",
      "para  0.015358319629443567 iteration  1041\n",
      "para  0.015302025215039717 iteration  1042\n",
      "para  0.01534897918594133 iteration  1043\n",
      "para  0.015318231953614998 iteration  1044\n",
      "para  0.015362165294134962 iteration  1045\n",
      "para  0.01529761469978946 iteration  1046\n",
      "para  0.015354064534650616 iteration  1047\n",
      "para  0.015337964983426525 iteration  1048\n",
      "para  0.015389268689295304 iteration  1049\n",
      "para  0.015307426987226312 iteration  1050\n",
      "para  0.015369129629880171 iteration  1051\n",
      "para  0.015349653220765251 iteration  1052\n",
      "para  0.015397749500997135 iteration  1053\n",
      "para  0.015316780906223609 iteration  1054\n",
      "para  0.01537453668895687 iteration  1055\n",
      "para  0.01537660177506168 iteration  1056\n",
      "para  0.015406268313331143 iteration  1057\n",
      "para  0.015340029947000903 iteration  1058\n",
      "para  0.015387743856621996 iteration  1059\n",
      "para  0.015364949803913532 iteration  1060\n",
      "para  0.015407747258131377 iteration  1061\n",
      "para  0.01534558511397006 iteration  1062\n",
      "para  0.015402817509116437 iteration  1063\n",
      "para  0.015376298033164166 iteration  1064\n",
      "para  0.015415998889089335 iteration  1065\n",
      "para  0.015356693595858163 iteration  1066\n",
      "para  0.01540859285375435 iteration  1067\n",
      "para  0.015396296556378378 iteration  1068\n",
      "para  0.015445053632144075 iteration  1069\n",
      "para  0.015363626707114376 iteration  1070\n",
      "para  0.015425116024422838 iteration  1071\n",
      "para  0.015412251667136195 iteration  1072\n",
      "para  0.01546039667845329 iteration  1073\n",
      "para  0.015385531637337616 iteration  1074\n",
      "para  0.015442595921108844 iteration  1075\n",
      "para  0.015425240345419615 iteration  1076\n",
      "para  0.015467503314698984 iteration  1077\n",
      "para  0.015401956941751662 iteration  1078\n",
      "para  0.01545994350160701 iteration  1079\n",
      "para  0.015422112545647971 iteration  1080\n",
      "para  0.015461871078552389 iteration  1081\n",
      "para  0.015412920952816388 iteration  1082\n",
      "para  0.015468129606794787 iteration  1083\n",
      "para  0.01543866892332943 iteration  1084\n",
      "para  0.015486162398080405 iteration  1085\n",
      "para  0.01541726448420278 iteration  1086\n",
      "para  0.01547926261767447 iteration  1087\n",
      "para  0.01546193070217893 iteration  1088\n",
      "para  0.015515065736489735 iteration  1089\n",
      "para  0.015429949160961144 iteration  1090\n",
      "para  0.015486671192560267 iteration  1091\n",
      "para  0.01548774794873215 iteration  1092\n",
      "para  0.015520936622088642 iteration  1093\n",
      "para  0.015463897873872832 iteration  1094\n",
      "para  0.015506158781264556 iteration  1095\n",
      "para  0.015471840548491236 iteration  1096\n",
      "para  0.015506304047715785 iteration  1097\n",
      "para  0.015469675359293552 iteration  1098\n",
      "para  0.015506774835765817 iteration  1099\n",
      "para  0.015476302203285238 iteration  1100\n",
      "Cost after iteration 1100: 0.272700\n",
      "para  0.015511812219521968 iteration  1101\n",
      "para  0.015477726898786542 iteration  1102\n",
      "para  0.015518166024907314 iteration  1103\n",
      "para  0.015476904458252512 iteration  1104\n",
      "para  0.01551652171452472 iteration  1105\n",
      "para  0.01548220322241058 iteration  1106\n",
      "para  0.015515446784176405 iteration  1107\n",
      "para  0.015485048358285998 iteration  1108\n",
      "para  0.015519482222394194 iteration  1109\n",
      "para  0.015491863711853132 iteration  1110\n",
      "para  0.015527337054164304 iteration  1111\n",
      "para  0.015492353636417234 iteration  1112\n",
      "para  0.015530740453650027 iteration  1113\n",
      "para  0.015476771793748782 iteration  1114\n",
      "para  0.015519800076556726 iteration  1115\n",
      "para  0.015503947453235318 iteration  1116\n",
      "para  0.015540161281560477 iteration  1117\n",
      "para  0.015491559333759355 iteration  1118\n",
      "para  0.015531016557155585 iteration  1119\n",
      "para  0.015508030367796435 iteration  1120\n",
      "para  0.015545229629029919 iteration  1121\n",
      "para  0.015496565459426088 iteration  1122\n",
      "para  0.01553844495878727 iteration  1123\n",
      "para  0.01550493335180858 iteration  1124\n",
      "para  0.015538586209540978 iteration  1125\n",
      "para  0.015511557410569818 iteration  1126\n",
      "para  0.015549703640201506 iteration  1127\n",
      "para  0.01550426491230348 iteration  1128\n",
      "para  0.015543291034414016 iteration  1129\n",
      "para  0.015524927648939351 iteration  1130\n",
      "para  0.015564518299315747 iteration  1131\n",
      "para  0.015507320599650591 iteration  1132\n",
      "para  0.015548780762015182 iteration  1133\n",
      "para  0.015534054558685883 iteration  1134\n",
      "para  0.01556937641132885 iteration  1135\n",
      "para  0.015513994483581947 iteration  1136\n",
      "para  0.015556190106412487 iteration  1137\n",
      "para  0.015540916889198085 iteration  1138\n",
      "para  0.015580886397762651 iteration  1139\n",
      "para  0.015508169929743066 iteration  1140\n",
      "para  0.01556185856607154 iteration  1141\n",
      "para  0.015555153922252459 iteration  1142\n",
      "para  0.015597162230259939 iteration  1143\n",
      "para  0.015515950700431786 iteration  1144\n",
      "para  0.015572662012286916 iteration  1145\n",
      "para  0.015564876258963248 iteration  1146\n",
      "para  0.015609405211156939 iteration  1147\n",
      "para  0.01551305780634634 iteration  1148\n",
      "para  0.015582338342052826 iteration  1149\n",
      "para  0.015575941209582079 iteration  1150\n",
      "para  0.015622049963751617 iteration  1151\n",
      "para  0.015536250014556854 iteration  1152\n",
      "para  0.015606152963339366 iteration  1153\n",
      "para  0.015588478901996395 iteration  1154\n",
      "para  0.01562316545413273 iteration  1155\n",
      "para  0.01557866259454929 iteration  1156\n",
      "para  0.015614567966881217 iteration  1157\n",
      "para  0.015601563184877293 iteration  1158\n",
      "para  0.015633251421527737 iteration  1159\n",
      "para  0.0155927561016757 iteration  1160\n",
      "para  0.01562836114258227 iteration  1161\n",
      "para  0.015588354688198424 iteration  1162\n",
      "para  0.015621856635104061 iteration  1163\n",
      "para  0.015588280959308932 iteration  1164\n",
      "para  0.015621781200929446 iteration  1165\n",
      "para  0.015611013268070939 iteration  1166\n",
      "para  0.015637795663570337 iteration  1167\n",
      "para  0.015615205561746944 iteration  1168\n",
      "para  0.01564148498938171 iteration  1169\n",
      "para  0.015619552059352525 iteration  1170\n",
      "para  0.015646345955632607 iteration  1171\n",
      "para  0.01561936936326287 iteration  1172\n",
      "para  0.01564850820856766 iteration  1173\n",
      "para  0.01561843601595327 iteration  1174\n",
      "para  0.015653336747746195 iteration  1175\n",
      "para  0.015607280429774802 iteration  1176\n",
      "para  0.01564317866405262 iteration  1177\n",
      "para  0.015629838977217887 iteration  1178\n",
      "para  0.01565770124353356 iteration  1179\n",
      "para  0.015611464834175156 iteration  1180\n",
      "para  0.01564618403073297 iteration  1181\n",
      "para  0.015639067737107173 iteration  1182\n",
      "para  0.01566957535558368 iteration  1183\n",
      "para  0.01562274232752222 iteration  1184\n",
      "para  0.015657592057127034 iteration  1185\n",
      "para  0.015649197240829995 iteration  1186\n",
      "para  0.01568050786898135 iteration  1187\n",
      "para  0.015626972500321794 iteration  1188\n",
      "para  0.015663617370032912 iteration  1189\n",
      "para  0.015654629517745024 iteration  1190\n",
      "para  0.015682749089377543 iteration  1191\n",
      "para  0.015632930846853153 iteration  1192\n",
      "para  0.015669972791448397 iteration  1193\n",
      "para  0.015664578199922508 iteration  1194\n",
      "para  0.015690760551315495 iteration  1195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.015647998757024995 iteration  1196\n",
      "para  0.015685212456737985 iteration  1197\n",
      "para  0.015655292364626698 iteration  1198\n",
      "para  0.015693131221902884 iteration  1199\n",
      "para  0.015643058871105543 iteration  1200\n",
      "Cost after iteration 1200: 0.237419\n",
      "para  0.015679766445938402 iteration  1201\n",
      "para  0.015671476090974957 iteration  1202\n",
      "para  0.015699357720544777 iteration  1203\n",
      "para  0.015648492620583803 iteration  1204\n",
      "para  0.015683509862382972 iteration  1205\n",
      "para  0.015680989736832376 iteration  1206\n",
      "para  0.01571295820648957 iteration  1207\n",
      "para  0.015668312153963953 iteration  1208\n",
      "para  0.01570513501845586 iteration  1209\n",
      "para  0.015683262467887888 iteration  1210\n",
      "para  0.01571844502760743 iteration  1211\n",
      "para  0.015667689625725963 iteration  1212\n",
      "para  0.015701838844100948 iteration  1213\n",
      "para  0.01569427943529329 iteration  1214\n",
      "para  0.015724807045289294 iteration  1215\n",
      "para  0.015675686498516132 iteration  1216\n",
      "para  0.01570915868151352 iteration  1217\n",
      "para  0.015708284581412556 iteration  1218\n",
      "para  0.015735343598857407 iteration  1219\n",
      "para  0.01569451326636809 iteration  1220\n",
      "para  0.015729456736125115 iteration  1221\n",
      "para  0.015706515795602612 iteration  1222\n",
      "para  0.01574101941068766 iteration  1223\n",
      "para  0.01568753790936535 iteration  1224\n",
      "para  0.015728811306183726 iteration  1225\n",
      "para  0.01571359042590334 iteration  1226\n",
      "para  0.015754950280832913 iteration  1227\n",
      "para  0.015692483222206937 iteration  1228\n",
      "para  0.015735351645204208 iteration  1229\n",
      "para  0.015740547843072352 iteration  1230\n",
      "para  0.015774202303043026 iteration  1231\n",
      "para  0.015707011680953644 iteration  1232\n",
      "para  0.0157516888937956 iteration  1233\n",
      "para  0.015748817699197157 iteration  1234\n",
      "para  0.015787613443838323 iteration  1235\n",
      "para  0.01570960458137935 iteration  1236\n",
      "para  0.015761615022206268 iteration  1237\n",
      "para  0.01576467482666347 iteration  1238\n",
      "para  0.015808501398820382 iteration  1239\n",
      "para  0.015706488895573426 iteration  1240\n",
      "para  0.0157699462768003 iteration  1241\n",
      "para  0.015769094817007744 iteration  1242\n",
      "para  0.015820927891926947 iteration  1243\n",
      "para  0.015707103245250844 iteration  1244\n",
      "para  0.015772595312117037 iteration  1245\n",
      "para  0.015774083178308706 iteration  1246\n",
      "para  0.015827932374045 iteration  1247\n",
      "para  0.015757629687697165 iteration  1248\n",
      "para  0.015818951404058076 iteration  1249\n",
      "para  0.01578310068439158 iteration  1250\n",
      "para  0.015816018999580756 iteration  1251\n",
      "para  0.015777267869966378 iteration  1252\n",
      "para  0.01581102777352989 iteration  1253\n",
      "para  0.015799621557385086 iteration  1254\n",
      "para  0.015820924139630328 iteration  1255\n",
      "para  0.01579689148659472 iteration  1256\n",
      "para  0.01581929376818924 iteration  1257\n",
      "para  0.0158037936866218 iteration  1258\n",
      "para  0.01582310021806187 iteration  1259\n",
      "para  0.015806431733613988 iteration  1260\n",
      "para  0.01582531788714798 iteration  1261\n",
      "para  0.01581068018020457 iteration  1262\n",
      "para  0.015828371141169917 iteration  1263\n",
      "para  0.015809728763321505 iteration  1264\n",
      "para  0.015829339273422362 iteration  1265\n",
      "para  0.015819583721083323 iteration  1266\n",
      "para  0.015836128997224478 iteration  1267\n",
      "para  0.01581532876870285 iteration  1268\n",
      "para  0.015839456288773607 iteration  1269\n",
      "para  0.015828131494435148 iteration  1270\n",
      "para  0.0158459863709764 iteration  1271\n",
      "para  0.015817764307375814 iteration  1272\n",
      "para  0.01584726173741695 iteration  1273\n",
      "para  0.015825054486772076 iteration  1274\n",
      "para  0.01585792441048983 iteration  1275\n",
      "para  0.015819072748275962 iteration  1276\n",
      "para  0.015853806962346558 iteration  1277\n",
      "para  0.015849471906333235 iteration  1278\n",
      "para  0.015871593065078828 iteration  1279\n",
      "para  0.01584323945299878 iteration  1280\n",
      "para  0.015873174674789978 iteration  1281\n",
      "para  0.01585163361397418 iteration  1282\n",
      "para  0.01587785590182584 iteration  1283\n",
      "para  0.01584884708363314 iteration  1284\n",
      "para  0.015879535852697652 iteration  1285\n",
      "para  0.015871227570708385 iteration  1286\n",
      "para  0.015892041887401044 iteration  1287\n",
      "para  0.015858430271566068 iteration  1288\n",
      "para  0.015888505356946293 iteration  1289\n",
      "para  0.015886448118647423 iteration  1290\n",
      "para  0.015903824119552157 iteration  1291\n",
      "para  0.01587703289070284 iteration  1292\n",
      "para  0.015903395088725316 iteration  1293\n",
      "para  0.015892739493574972 iteration  1294\n",
      "para  0.01590772728731377 iteration  1295\n",
      "para  0.015887955233536033 iteration  1296\n",
      "para  0.01590847405869104 iteration  1297\n",
      "para  0.015905659947254097 iteration  1298\n",
      "para  0.015919596755717486 iteration  1299\n",
      "para  0.015900980840445403 iteration  1300\n",
      "Cost after iteration 1300: 0.199601\n",
      "para  0.015922629245863518 iteration  1301\n",
      "para  0.01590504058059379 iteration  1302\n",
      "para  0.01592604850472653 iteration  1303\n",
      "para  0.015900409526554107 iteration  1304\n",
      "para  0.01593192037714355 iteration  1305\n",
      "para  0.015902927336119872 iteration  1306\n",
      "para  0.01594098258764714 iteration  1307\n",
      "para  0.015890767176895082 iteration  1308\n",
      "para  0.015928196687087694 iteration  1309\n",
      "para  0.015925879316552517 iteration  1310\n",
      "para  0.015948004225035624 iteration  1311\n",
      "para  0.01592168639641574 iteration  1312\n",
      "para  0.01594852804814388 iteration  1313\n",
      "para  0.015948854064521793 iteration  1314\n",
      "para  0.015963638720485656 iteration  1315\n",
      "para  0.01594337125550726 iteration  1316\n",
      "para  0.015966876667072 iteration  1317\n",
      "para  0.015958018369082144 iteration  1318\n",
      "para  0.015972117326912123 iteration  1319\n",
      "para  0.015953890240917423 iteration  1320\n",
      "para  0.015973223123044646 iteration  1321\n",
      "para  0.015963095825603214 iteration  1322\n",
      "para  0.015976252474365037 iteration  1323\n",
      "para  0.015956136023450446 iteration  1324\n",
      "para  0.015978420180459904 iteration  1325\n",
      "para  0.015968676752238592 iteration  1326\n",
      "para  0.015981490874305795 iteration  1327\n",
      "para  0.015958032778288934 iteration  1328\n",
      "para  0.015981531544556615 iteration  1329\n",
      "para  0.015974687741424846 iteration  1330\n",
      "para  0.015995680777658772 iteration  1331\n",
      "para  0.01595568923358844 iteration  1332\n",
      "para  0.015987335374845854 iteration  1333\n",
      "para  0.015979372989199252 iteration  1334\n",
      "para  0.016001980057652198 iteration  1335\n",
      "para  0.01595794703003147 iteration  1336\n",
      "para  0.01598921199854405 iteration  1337\n",
      "para  0.015990231453902624 iteration  1338\n",
      "para  0.016018522808735648 iteration  1339\n",
      "para  0.015966892127555695 iteration  1340\n",
      "para  0.01599788420772937 iteration  1341\n",
      "para  0.016000704675100817 iteration  1342\n",
      "para  0.01603087019515104 iteration  1343\n",
      "para  0.015977702984194778 iteration  1344\n",
      "para  0.01600849674912691 iteration  1345\n",
      "para  0.01601110595428654 iteration  1346\n",
      "para  0.01604030400090267 iteration  1347\n",
      "para  0.01598812486792659 iteration  1348\n",
      "para  0.01601725435139513 iteration  1349\n",
      "para  0.016019548644142657 iteration  1350\n",
      "para  0.016038121544930388 iteration  1351\n",
      "para  0.016006721536712135 iteration  1352\n",
      "para  0.016031744530568222 iteration  1353\n",
      "para  0.016018977577359032 iteration  1354\n",
      "para  0.016038373521018293 iteration  1355\n",
      "para  0.01601832896967204 iteration  1356\n",
      "para  0.01603971746267248 iteration  1357\n",
      "para  0.016033016558329193 iteration  1358\n",
      "para  0.016044184916080277 iteration  1359\n",
      "para  0.016034939333045048 iteration  1360\n",
      "para  0.01604710815086907 iteration  1361\n",
      "para  0.01604089645104978 iteration  1362\n",
      "para  0.01604400961279264 iteration  1363\n",
      "para  0.016038276931853168 iteration  1364\n",
      "para  0.01604648472529037 iteration  1365\n",
      "para  0.01603940585568235 iteration  1366\n",
      "para  0.01605021756402918 iteration  1367\n",
      "para  0.016029740415230014 iteration  1368\n",
      "para  0.016049247997342485 iteration  1369\n",
      "para  0.016039467118951215 iteration  1370\n",
      "para  0.016055399191551425 iteration  1371\n",
      "para  0.016028080922602335 iteration  1372\n",
      "para  0.016052096674989236 iteration  1373\n",
      "para  0.016051921681263875 iteration  1374\n",
      "para  0.016064787441692433 iteration  1375\n",
      "para  0.016043519706292166 iteration  1376\n",
      "para  0.016063281435412798 iteration  1377\n",
      "para  0.01605645358709554 iteration  1378\n",
      "para  0.016070393730857356 iteration  1379\n",
      "para  0.01605169420854974 iteration  1380\n",
      "para  0.016071330886748173 iteration  1381\n",
      "para  0.01604853623569258 iteration  1382\n",
      "para  0.016072135288529438 iteration  1383\n",
      "para  0.016037482727777955 iteration  1384\n",
      "para  0.016064697380345064 iteration  1385\n",
      "para  0.016062833200646685 iteration  1386\n",
      "para  0.016085891982991058 iteration  1387\n",
      "para  0.016036326973990964 iteration  1388\n",
      "para  0.01606587921839607 iteration  1389\n",
      "para  0.016067338987158175 iteration  1390\n",
      "para  0.016100857005788678 iteration  1391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.01604237847918312 iteration  1392\n",
      "para  0.01607290359914151 iteration  1393\n",
      "para  0.016072032301335595 iteration  1394\n",
      "para  0.0161048475476878 iteration  1395\n",
      "para  0.016051604813338973 iteration  1396\n",
      "para  0.01608021935098836 iteration  1397\n",
      "para  0.016081125255845912 iteration  1398\n",
      "para  0.016108041683018538 iteration  1399\n",
      "para  0.01606130466489108 iteration  1400\n",
      "Cost after iteration 1400: 0.189263\n",
      "para  0.016093892478602923 iteration  1401\n",
      "para  0.01607860123303712 iteration  1402\n",
      "para  0.016112450799230304 iteration  1403\n",
      "para  0.016054260485782117 iteration  1404\n",
      "para  0.0160867595199724 iteration  1405\n",
      "para  0.01608621689830712 iteration  1406\n",
      "para  0.01612002813776343 iteration  1407\n",
      "para  0.01605235920587354 iteration  1408\n",
      "para  0.016092012002272008 iteration  1409\n",
      "para  0.016092112189187515 iteration  1410\n",
      "para  0.016128144409363884 iteration  1411\n",
      "para  0.0160463936059352 iteration  1412\n",
      "para  0.016092928051771857 iteration  1413\n",
      "para  0.016090337068028635 iteration  1414\n",
      "para  0.016135303115743963 iteration  1415\n",
      "para  0.016016864965775725 iteration  1416\n",
      "para  0.016086213875405847 iteration  1417\n",
      "para  0.016080409656421858 iteration  1418\n",
      "para  0.01613467326742914 iteration  1419\n",
      "para  0.016060551535811814 iteration  1420\n",
      "para  0.016126879751823815 iteration  1421\n",
      "para  0.016096576773028205 iteration  1422\n",
      "para  0.016127171010952752 iteration  1423\n",
      "para  0.01610238299281553 iteration  1424\n",
      "para  0.016122310272530162 iteration  1425\n",
      "para  0.01612283568866433 iteration  1426\n",
      "para  0.01613072445875472 iteration  1427\n",
      "para  0.016128822513892044 iteration  1428\n",
      "para  0.016136440203485838 iteration  1429\n",
      "para  0.016127839419605584 iteration  1430\n",
      "para  0.01613843853776601 iteration  1431\n",
      "para  0.016130990239980207 iteration  1432\n",
      "para  0.016139394860906285 iteration  1433\n",
      "para  0.016132845698744798 iteration  1434\n",
      "para  0.016141730401895118 iteration  1435\n",
      "para  0.0161323628262486 iteration  1436\n",
      "para  0.016142529955345254 iteration  1437\n",
      "para  0.016134358383604188 iteration  1438\n",
      "para  0.016142216414489263 iteration  1439\n",
      "para  0.016133706363093345 iteration  1440\n",
      "para  0.016143676649554784 iteration  1441\n",
      "para  0.016135200423479237 iteration  1442\n",
      "para  0.016145648158837674 iteration  1443\n",
      "para  0.016132437908007398 iteration  1444\n",
      "para  0.01614265390855252 iteration  1445\n",
      "para  0.016129224746266116 iteration  1446\n",
      "para  0.01614115458960401 iteration  1447\n",
      "para  0.01613356467803398 iteration  1448\n",
      "para  0.016142051119971697 iteration  1449\n",
      "para  0.016133026627286374 iteration  1450\n",
      "para  0.016142654915771895 iteration  1451\n",
      "para  0.01613211249501064 iteration  1452\n",
      "para  0.016141413041587258 iteration  1453\n",
      "para  0.01612943623287409 iteration  1454\n",
      "para  0.016140893947219414 iteration  1455\n",
      "para  0.01613414999342739 iteration  1456\n",
      "para  0.016143370726194983 iteration  1457\n",
      "para  0.01612409853826292 iteration  1458\n",
      "para  0.01614107789515325 iteration  1459\n",
      "para  0.016134665749538476 iteration  1460\n",
      "para  0.016148603785728553 iteration  1461\n",
      "para  0.01613251577392915 iteration  1462\n",
      "para  0.01614657189765135 iteration  1463\n",
      "para  0.016144849872825735 iteration  1464\n",
      "para  0.016153221216189236 iteration  1465\n",
      "para  0.016148894529229414 iteration  1466\n",
      "para  0.016157780737467105 iteration  1467\n",
      "para  0.01614355289165218 iteration  1468\n",
      "para  0.016153752062339377 iteration  1469\n",
      "para  0.016139697775479685 iteration  1470\n",
      "para  0.0161511088808529 iteration  1471\n",
      "para  0.016140991131846607 iteration  1472\n",
      "para  0.01615216593193984 iteration  1473\n",
      "para  0.01614295820689693 iteration  1474\n",
      "para  0.016154250288536367 iteration  1475\n",
      "para  0.01615272792203943 iteration  1476\n",
      "para  0.01615637360852726 iteration  1477\n",
      "para  0.016147447793593468 iteration  1478\n",
      "para  0.016154011537435238 iteration  1479\n",
      "para  0.016148690399880063 iteration  1480\n",
      "para  0.016157099098440784 iteration  1481\n",
      "para  0.016147250326281826 iteration  1482\n",
      "para  0.016155948024221344 iteration  1483\n",
      "para  0.016147792315354622 iteration  1484\n",
      "para  0.016157156302171977 iteration  1485\n",
      "para  0.01613559582606814 iteration  1486\n",
      "para  0.016150160788256197 iteration  1487\n",
      "para  0.016150141541676953 iteration  1488\n",
      "para  0.016160401549383425 iteration  1489\n",
      "para  0.016154415498949824 iteration  1490\n",
      "para  0.01616045856818882 iteration  1491\n",
      "para  0.01615706603743453 iteration  1492\n",
      "para  0.016165179753976126 iteration  1493\n",
      "para  0.016146556376598276 iteration  1494\n",
      "para  0.01615792227394322 iteration  1495\n",
      "para  0.0161392695642087 iteration  1496\n",
      "para  0.01615489760136953 iteration  1497\n",
      "para  0.016158249660267895 iteration  1498\n",
      "para  0.01616288084519969 iteration  1499\n",
      "para  0.016152097262103392 iteration  1500\n",
      "Cost after iteration 1500: 0.161189\n",
      "para  0.01616341890428312 iteration  1501\n",
      "para  0.016156876731518104 iteration  1502\n",
      "para  0.01616597687868763 iteration  1503\n",
      "para  0.016142703292020735 iteration  1504\n",
      "para  0.016157816615659824 iteration  1505\n",
      "para  0.01615907543148079 iteration  1506\n",
      "para  0.01616431244298473 iteration  1507\n",
      "para  0.016150426089403466 iteration  1508\n",
      "para  0.01616295032914909 iteration  1509\n",
      "para  0.016155877234388185 iteration  1510\n",
      "para  0.01616655159493714 iteration  1511\n",
      "para  0.01614754642622532 iteration  1512\n",
      "para  0.016161926240770515 iteration  1513\n",
      "para  0.016163762433047343 iteration  1514\n",
      "para  0.016172849446196652 iteration  1515\n",
      "para  0.016147612979157153 iteration  1516\n",
      "para  0.016161979548156825 iteration  1517\n",
      "para  0.016163743262112725 iteration  1518\n",
      "para  0.016174117134738236 iteration  1519\n",
      "para  0.016146645902100708 iteration  1520\n",
      "para  0.016163671824699563 iteration  1521\n",
      "para  0.016168301709432398 iteration  1522\n",
      "para  0.0161759250805993 iteration  1523\n",
      "para  0.016162571627760962 iteration  1524\n",
      "para  0.016175906406774646 iteration  1525\n",
      "para  0.01616787855894047 iteration  1526\n",
      "para  0.016177332456084957 iteration  1527\n",
      "para  0.016169678134700414 iteration  1528\n",
      "para  0.01617972029936299 iteration  1529\n",
      "para  0.01616262111537744 iteration  1530\n",
      "para  0.016175621174219734 iteration  1531\n",
      "para  0.016155960518154867 iteration  1532\n",
      "para  0.016170977852621223 iteration  1533\n",
      "para  0.016174875115000573 iteration  1534\n",
      "para  0.016179034298452147 iteration  1535\n",
      "para  0.016175756406997654 iteration  1536\n",
      "para  0.016182636743583296 iteration  1537\n",
      "para  0.016170718341577364 iteration  1538\n",
      "para  0.016178879589391203 iteration  1539\n",
      "para  0.016174713430681973 iteration  1540\n",
      "para  0.016184065021736516 iteration  1541\n",
      "para  0.01616711574892091 iteration  1542\n",
      "para  0.016178497664663043 iteration  1543\n",
      "para  0.016160989317485015 iteration  1544\n",
      "para  0.01617559892893559 iteration  1545\n",
      "para  0.016177216046218898 iteration  1546\n",
      "para  0.016183892460082495 iteration  1547\n",
      "para  0.016166747694244282 iteration  1548\n",
      "para  0.016180313555141417 iteration  1549\n",
      "para  0.016182388418876224 iteration  1550\n",
      "para  0.016186279927002913 iteration  1551\n",
      "para  0.01618302066914419 iteration  1552\n",
      "para  0.016189675776586695 iteration  1553\n",
      "para  0.016170589928287446 iteration  1554\n",
      "para  0.01618198978458977 iteration  1555\n",
      "para  0.016167162553258962 iteration  1556\n",
      "para  0.016179316120507593 iteration  1557\n",
      "para  0.016185250813412367 iteration  1558\n",
      "para  0.016189492452207584 iteration  1559\n",
      "para  0.016187763828919 iteration  1560\n",
      "para  0.016184850144914137 iteration  1561\n",
      "para  0.016192028620718772 iteration  1562\n",
      "para  0.016175330976024912 iteration  1563\n",
      "para  0.016184576460910774 iteration  1564\n",
      "para  0.016176147877901392 iteration  1565\n",
      "para  0.016186890334070534 iteration  1566\n",
      "para  0.016180416540298833 iteration  1567\n",
      "para  0.01618797325047165 iteration  1568\n",
      "para  0.01618167304420385 iteration  1569\n",
      "para  0.016189914738300212 iteration  1570\n",
      "para  0.01617510333800175 iteration  1571\n",
      "para  0.016182766353008846 iteration  1572\n",
      "para  0.01617000293007545 iteration  1573\n",
      "para  0.01618333605605273 iteration  1574\n",
      "para  0.016183223996744198 iteration  1575\n",
      "para  0.016193235009179605 iteration  1576\n",
      "para  0.01616579119018736 iteration  1577\n",
      "para  0.016181768136909833 iteration  1578\n",
      "para  0.016188319686181493 iteration  1579\n",
      "para  0.016197241133028333 iteration  1580\n",
      "para  0.016173827781788355 iteration  1581\n",
      "para  0.016187969833409123 iteration  1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.01619420379708441 iteration  1583\n",
      "para  0.016200675880880144 iteration  1584\n",
      "para  0.01618554173395895 iteration  1585\n",
      "para  0.01619658403918971 iteration  1586\n",
      "para  0.01618260502802919 iteration  1587\n",
      "para  0.016195258027025056 iteration  1588\n",
      "para  0.01617678065135061 iteration  1589\n",
      "para  0.016190993519383745 iteration  1590\n",
      "para  0.016196836728487603 iteration  1591\n",
      "para  0.016203932897465186 iteration  1592\n",
      "para  0.01619391178930048 iteration  1593\n",
      "para  0.01620496671392599 iteration  1594\n",
      "para  0.016185578901734984 iteration  1595\n",
      "para  0.01619877596593904 iteration  1596\n",
      "para  0.016177734349783153 iteration  1597\n",
      "para  0.016192424979763413 iteration  1598\n",
      "para  0.016203870855187562 iteration  1599\n",
      "para  0.016209784989694127 iteration  1600\n",
      "Cost after iteration 1600: 0.148214\n",
      "para  0.01620398677263628 iteration  1601\n",
      "para  0.016205773551816616 iteration  1602\n",
      "para  0.01620715004976147 iteration  1603\n",
      "para  0.016206676130115893 iteration  1604\n",
      "para  0.01621385330711415 iteration  1605\n",
      "para  0.01619559868526992 iteration  1606\n",
      "para  0.01620539228327882 iteration  1607\n",
      "para  0.01620276817566345 iteration  1608\n",
      "para  0.016210822030059985 iteration  1609\n",
      "para  0.01619832543131148 iteration  1610\n",
      "para  0.016206524804088844 iteration  1611\n",
      "para  0.016195298931396745 iteration  1612\n",
      "para  0.01620678378741379 iteration  1613\n",
      "para  0.016202133337767755 iteration  1614\n",
      "para  0.01621065961748876 iteration  1615\n",
      "para  0.016185325389666883 iteration  1616\n",
      "para  0.016200090097402805 iteration  1617\n",
      "para  0.01620597587148963 iteration  1618\n",
      "para  0.01621435975288213 iteration  1619\n",
      "para  0.016195109930869263 iteration  1620\n",
      "para  0.01620726705887252 iteration  1621\n",
      "para  0.01620633163870839 iteration  1622\n",
      "para  0.01621527770968243 iteration  1623\n",
      "para  0.01619300076889063 iteration  1624\n",
      "para  0.016206746233624086 iteration  1625\n",
      "para  0.01621296100306046 iteration  1626\n",
      "para  0.01621942834412086 iteration  1627\n",
      "para  0.016212718703101533 iteration  1628\n",
      "para  0.016220287057594564 iteration  1629\n",
      "para  0.01619503447347655 iteration  1630\n",
      "para  0.016209273364988747 iteration  1631\n",
      "para  0.016201854890229576 iteration  1632\n",
      "para  0.016213071940379405 iteration  1633\n",
      "para  0.016215362817113863 iteration  1634\n",
      "para  0.016221903665164784 iteration  1635\n",
      "para  0.01621538692717763 iteration  1636\n",
      "para  0.016222859180577157 iteration  1637\n",
      "para  0.01620171823750709 iteration  1638\n",
      "para  0.016215201553706204 iteration  1639\n",
      "para  0.016194245261601667 iteration  1640\n",
      "para  0.016208768631548607 iteration  1641\n",
      "para  0.01622038632512446 iteration  1642\n",
      "para  0.016227293244994435 iteration  1643\n",
      "para  0.016210761059530385 iteration  1644\n",
      "para  0.016219385170481306 iteration  1645\n",
      "para  0.01621604557935998 iteration  1646\n",
      "para  0.016223173366717913 iteration  1647\n",
      "para  0.01622502709096609 iteration  1648\n",
      "para  0.016231469505764297 iteration  1649\n",
      "para  0.016218850118706843 iteration  1650\n",
      "para  0.016227632665270067 iteration  1651\n",
      "para  0.016214689633650883 iteration  1652\n",
      "para  0.01622370615206314 iteration  1653\n",
      "para  0.01621776575784152 iteration  1654\n",
      "para  0.016226545519553305 iteration  1655\n",
      "para  0.016230394144825893 iteration  1656\n",
      "para  0.016232497560850427 iteration  1657\n",
      "para  0.016212388347381878 iteration  1658\n",
      "para  0.01622322663734031 iteration  1659\n",
      "para  0.01620278328158969 iteration  1660\n",
      "para  0.016216368839948377 iteration  1661\n",
      "para  0.016231337937117455 iteration  1662\n",
      "para  0.01623313520701739 iteration  1663\n",
      "para  0.016218744243236126 iteration  1664\n",
      "para  0.016230198345681245 iteration  1665\n",
      "para  0.01620763352948044 iteration  1666\n",
      "para  0.016221789755746736 iteration  1667\n",
      "para  0.01623295520492398 iteration  1668\n",
      "para  0.016240239073881096 iteration  1669\n",
      "para  0.016213127515475798 iteration  1670\n",
      "para  0.01622716699994162 iteration  1671\n",
      "para  0.01622985904246875 iteration  1672\n",
      "para  0.016234607009622527 iteration  1673\n",
      "para  0.016234041239929033 iteration  1674\n",
      "para  0.01623389711698678 iteration  1675\n",
      "para  0.01623865621915975 iteration  1676\n",
      "para  0.01623056770687513 iteration  1677\n",
      "para  0.016240547569938164 iteration  1678\n",
      "para  0.016235978374215313 iteration  1679\n",
      "para  0.01624508945700073 iteration  1680\n",
      "para  0.016225071494910953 iteration  1681\n",
      "para  0.01623670973317402 iteration  1682\n",
      "para  0.016241847684144165 iteration  1683\n",
      "para  0.01624869231833529 iteration  1684\n",
      "para  0.016234557124443244 iteration  1685\n",
      "para  0.016244696941480855 iteration  1686\n",
      "para  0.01624609973731683 iteration  1687\n",
      "para  0.01625274179948013 iteration  1688\n",
      "para  0.0162448632719513 iteration  1689\n",
      "para  0.016249767854623877 iteration  1690\n",
      "para  0.016252732413448358 iteration  1691\n",
      "para  0.01624184168516915 iteration  1692\n",
      "para  0.016249494175589938 iteration  1693\n",
      "para  0.0162475848189262 iteration  1694\n",
      "para  0.016254488244518178 iteration  1695\n",
      "para  0.016244221317600286 iteration  1696\n",
      "para  0.01625135112414489 iteration  1697\n",
      "para  0.016229050200650463 iteration  1698\n",
      "para  0.016242511187466804 iteration  1699\n",
      "para  0.016246234870469972 iteration  1700\n",
      "Cost after iteration 1700: 0.137775\n",
      "para  0.016242897428731033 iteration  1701\n",
      "para  0.016250716478258893 iteration  1702\n",
      "para  0.016236504383559846 iteration  1703\n",
      "para  0.01624662166990631 iteration  1704\n",
      "para  0.016238285145707066 iteration  1705\n",
      "para  0.01624866579895171 iteration  1706\n",
      "para  0.016253349789730576 iteration  1707\n",
      "para  0.01625130413308076 iteration  1708\n",
      "para  0.01625260945920436 iteration  1709\n",
      "para  0.01625939970296786 iteration  1710\n",
      "para  0.016227780987608516 iteration  1711\n",
      "para  0.01624135404088793 iteration  1712\n",
      "para  0.016251024636092 iteration  1713\n",
      "para  0.01625010713265462 iteration  1714\n",
      "para  0.01625844632004018 iteration  1715\n",
      "para  0.016238215316884366 iteration  1716\n",
      "para  0.016252745470639953 iteration  1717\n",
      "para  0.0162497743263036 iteration  1718\n",
      "para  0.016258940128409012 iteration  1719\n",
      "para  0.01625789612489997 iteration  1720\n",
      "para  0.016260817399963535 iteration  1721\n",
      "para  0.016258416548315016 iteration  1722\n",
      "para  0.016257159352100033 iteration  1723\n",
      "para  0.01626233266497697 iteration  1724\n",
      "para  0.01624111467814162 iteration  1725\n",
      "para  0.016253215159226383 iteration  1726\n",
      "para  0.01625600637621219 iteration  1727\n",
      "para  0.016264182483222603 iteration  1728\n",
      "para  0.016245773482822863 iteration  1729\n",
      "para  0.016257391549312623 iteration  1730\n",
      "para  0.016265813848293103 iteration  1731\n",
      "para  0.01627148851653155 iteration  1732\n",
      "para  0.016262249669281532 iteration  1733\n",
      "para  0.016271606294328184 iteration  1734\n",
      "para  0.01625736247959026 iteration  1735\n",
      "para  0.01626672223779795 iteration  1736\n",
      "para  0.016246831525566864 iteration  1737\n",
      "para  0.0162591051559938 iteration  1738\n",
      "para  0.016272789536107845 iteration  1739\n",
      "para  0.016263850284103088 iteration  1740\n",
      "para  0.016270566152405595 iteration  1741\n",
      "para  0.01625533062310195 iteration  1742\n",
      "para  0.01626591572989345 iteration  1743\n",
      "para  0.016275982141137606 iteration  1744\n",
      "para  0.016280211451326715 iteration  1745\n",
      "para  0.01625657284735685 iteration  1746\n",
      "para  0.01626784157342567 iteration  1747\n",
      "para  0.016266723177922243 iteration  1748\n",
      "para  0.01627493819292972 iteration  1749\n",
      "para  0.016275202821985173 iteration  1750\n",
      "para  0.016283412923641848 iteration  1751\n",
      "para  0.016259209190341687 iteration  1752\n",
      "para  0.016270782039159305 iteration  1753\n",
      "para  0.016274406028304718 iteration  1754\n",
      "para  0.01627839387477095 iteration  1755\n",
      "para  0.01627576859211396 iteration  1756\n",
      "para  0.016284446530599864 iteration  1757\n",
      "para  0.016265931817511892 iteration  1758\n",
      "para  0.01627746230749108 iteration  1759\n",
      "para  0.016281131120684272 iteration  1760\n",
      "para  0.01627662034729248 iteration  1761\n",
      "para  0.016284701110829622 iteration  1762\n",
      "para  0.016277425997064932 iteration  1763\n",
      "para  0.01628458949083997 iteration  1764\n",
      "para  0.01628067990592532 iteration  1765\n",
      "para  0.01629137154860928 iteration  1766\n",
      "para  0.016263560611410134 iteration  1767\n",
      "para  0.01627582110295118 iteration  1768\n",
      "para  0.016282082782275376 iteration  1769\n",
      "para  0.016270373897380144 iteration  1770\n",
      "para  0.016279568255618753 iteration  1771\n",
      "para  0.01628360323031965 iteration  1772\n",
      "para  0.01628920330141872 iteration  1773\n",
      "para  0.016277047550931626 iteration  1774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.016287429994379585 iteration  1775\n",
      "para  0.016287745884723148 iteration  1776\n",
      "para  0.01629586672010102 iteration  1777\n",
      "para  0.01628112578959334 iteration  1778\n",
      "para  0.016291494366669237 iteration  1779\n",
      "para  0.016295060441120644 iteration  1780\n",
      "para  0.016300818270386812 iteration  1781\n",
      "para  0.016296767874750626 iteration  1782\n",
      "para  0.016304894856747083 iteration  1783\n",
      "para  0.016288816241768603 iteration  1784\n",
      "para  0.01629634913698362 iteration  1785\n",
      "para  0.016288652320384994 iteration  1786\n",
      "para  0.016297798387637095 iteration  1787\n",
      "para  0.016306635837273317 iteration  1788\n",
      "para  0.016309453794820045 iteration  1789\n",
      "para  0.016306458345230843 iteration  1790\n",
      "para  0.01629840761751375 iteration  1791\n",
      "para  0.016303940508635033 iteration  1792\n",
      "para  0.016285753013665853 iteration  1793\n",
      "para  0.01629671008142319 iteration  1794\n",
      "para  0.016304333389687224 iteration  1795\n",
      "para  0.016311207339513543 iteration  1796\n",
      "para  0.016304763628256808 iteration  1797\n",
      "para  0.016312037336314304 iteration  1798\n",
      "para  0.01630998899846238 iteration  1799\n",
      "para  0.016305765463445903 iteration  1800\n",
      "Cost after iteration 1800: 0.129740\n",
      "para  0.01631039764889542 iteration  1801\n",
      "para  0.01629479421326944 iteration  1802\n",
      "para  0.016304270357523014 iteration  1803\n",
      "para  0.016312489654505175 iteration  1804\n",
      "para  0.016318314853009563 iteration  1805\n",
      "para  0.01631111383558679 iteration  1806\n",
      "para  0.016310058200717913 iteration  1807\n",
      "para  0.016315681580993703 iteration  1808\n",
      "para  0.01630481258290338 iteration  1809\n",
      "para  0.016313566400166003 iteration  1810\n",
      "para  0.016324856846328586 iteration  1811\n",
      "para  0.016325148239837432 iteration  1812\n",
      "para  0.016305935016735357 iteration  1813\n",
      "para  0.01631311308577935 iteration  1814\n",
      "para  0.016300904725939504 iteration  1815\n",
      "para  0.01631027259038695 iteration  1816\n",
      "para  0.016322622924056406 iteration  1817\n",
      "para  0.016312619258883783 iteration  1818\n",
      "para  0.01631921835218715 iteration  1819\n",
      "para  0.016312631484770707 iteration  1820\n",
      "para  0.016320396557190153 iteration  1821\n",
      "para  0.016312583554882378 iteration  1822\n",
      "para  0.016319699439731206 iteration  1823\n",
      "para  0.01630213567210418 iteration  1824\n",
      "para  0.01631290681894037 iteration  1825\n",
      "para  0.016323255077148994 iteration  1826\n",
      "para  0.016319407606424183 iteration  1827\n",
      "para  0.0163261869663852 iteration  1828\n",
      "para  0.016307681734292295 iteration  1829\n",
      "para  0.01631826332068804 iteration  1830\n",
      "para  0.016328820946748365 iteration  1831\n",
      "para  0.016323267232525737 iteration  1832\n",
      "para  0.016329828885491355 iteration  1833\n",
      "para  0.016310879684361214 iteration  1834\n",
      "para  0.016321581269581165 iteration  1835\n",
      "para  0.016331684169548437 iteration  1836\n",
      "para  0.016327625929493078 iteration  1837\n",
      "para  0.01633483216050382 iteration  1838\n",
      "para  0.01631533487232377 iteration  1839\n",
      "para  0.016326527895063177 iteration  1840\n",
      "para  0.016336155824884225 iteration  1841\n",
      "para  0.016334502045377 iteration  1842\n",
      "para  0.016341729193254304 iteration  1843\n",
      "para  0.016324405115285653 iteration  1844\n",
      "para  0.01633444330454905 iteration  1845\n",
      "para  0.01634219951186521 iteration  1846\n",
      "para  0.016346619088750253 iteration  1847\n",
      "para  0.016346234393258243 iteration  1848\n",
      "para  0.016332872721687482 iteration  1849\n",
      "para  0.016339481567779018 iteration  1850\n",
      "para  0.01633230795010927 iteration  1851\n",
      "para  0.016340314615631547 iteration  1852\n",
      "para  0.01635007869071127 iteration  1853\n",
      "para  0.016339024915299233 iteration  1854\n",
      "para  0.016345323612213795 iteration  1855\n",
      "para  0.016343566911951154 iteration  1856\n",
      "para  0.016347874731757413 iteration  1857\n",
      "para  0.016350470288704753 iteration  1858\n",
      "para  0.016349201057533114 iteration  1859\n",
      "para  0.016340391138715223 iteration  1860\n",
      "para  0.016348288797413398 iteration  1861\n",
      "para  0.016330360271205192 iteration  1862\n",
      "para  0.016340836429508784 iteration  1863\n",
      "para  0.016349615474587718 iteration  1864\n",
      "para  0.016351187733977916 iteration  1865\n",
      "para  0.01635748026962503 iteration  1866\n",
      "para  0.016346589390737007 iteration  1867\n",
      "para  0.01635444344308546 iteration  1868\n",
      "para  0.01636285888090875 iteration  1869\n",
      "para  0.016339224894981665 iteration  1870\n",
      "para  0.01634759442486907 iteration  1871\n",
      "para  0.01635294279996961 iteration  1872\n",
      "para  0.016350095657633696 iteration  1873\n",
      "para  0.016357203555882292 iteration  1874\n",
      "para  0.01635987220376681 iteration  1875\n",
      "para  0.016367631193700896 iteration  1876\n",
      "para  0.01633795158081317 iteration  1877\n",
      "para  0.016347685302212388 iteration  1878\n",
      "para  0.016353712175378846 iteration  1879\n",
      "para  0.016356791995014754 iteration  1880\n",
      "para  0.016362661327093377 iteration  1881\n",
      "para  0.0163584443294115 iteration  1882\n",
      "para  0.01636572357890718 iteration  1883\n",
      "para  0.016366262358859143 iteration  1884\n",
      "para  0.01637060944515837 iteration  1885\n",
      "para  0.016354883313497236 iteration  1886\n",
      "para  0.016362537674719516 iteration  1887\n",
      "para  0.01636705834910553 iteration  1888\n",
      "para  0.016361773760382333 iteration  1889\n",
      "para  0.0163695104341009 iteration  1890\n",
      "para  0.016362238463752805 iteration  1891\n",
      "para  0.016369840126284594 iteration  1892\n",
      "para  0.01636826259510768 iteration  1893\n",
      "para  0.016374194800865962 iteration  1894\n",
      "para  0.016351763022892065 iteration  1895\n",
      "para  0.01636245915813045 iteration  1896\n",
      "para  0.01636852837584288 iteration  1897\n",
      "para  0.01636311277898164 iteration  1898\n",
      "para  0.016370516040666826 iteration  1899\n",
      "para  0.016371008695156293 iteration  1900\n",
      "Cost after iteration 1900: 0.121225\n",
      "para  0.016376491246818947 iteration  1901\n",
      "para  0.01637469848103024 iteration  1902\n",
      "para  0.016367710180269772 iteration  1903\n",
      "para  0.01637342218543054 iteration  1904\n",
      "para  0.01635529042853988 iteration  1905\n",
      "para  0.016364915962955768 iteration  1906\n",
      "para  0.01637513095693332 iteration  1907\n",
      "para  0.016380797214572453 iteration  1908\n",
      "para  0.016364697432078402 iteration  1909\n",
      "para  0.016373225370583364 iteration  1910\n",
      "para  0.016377480046190697 iteration  1911\n",
      "para  0.01637487786667873 iteration  1912\n",
      "para  0.01638181603851157 iteration  1913\n",
      "para  0.0163825129005595 iteration  1914\n",
      "para  0.016386182070536777 iteration  1915\n",
      "para  0.016374512749191824 iteration  1916\n",
      "para  0.01638033750600611 iteration  1917\n",
      "para  0.01638014362252779 iteration  1918\n",
      "para  0.016385404309434297 iteration  1919\n",
      "para  0.016372761721324288 iteration  1920\n",
      "para  0.0163805943134225 iteration  1921\n",
      "para  0.016385399184667082 iteration  1922\n",
      "para  0.016373559045771677 iteration  1923\n",
      "para  0.016381653188587458 iteration  1924\n",
      "para  0.016387357312946445 iteration  1925\n",
      "para  0.016391695577439656 iteration  1926\n",
      "para  0.016373654757967128 iteration  1927\n",
      "para  0.01638132802230434 iteration  1928\n",
      "para  0.01638261580468398 iteration  1929\n",
      "para  0.016388993768477116 iteration  1930\n",
      "para  0.01637513168466878 iteration  1931\n",
      "para  0.01638339526554838 iteration  1932\n",
      "para  0.016389834084390514 iteration  1933\n",
      "para  0.016388518293342372 iteration  1934\n",
      "para  0.016393659504454032 iteration  1935\n",
      "para  0.016382877002073647 iteration  1936\n",
      "para  0.016390387778127236 iteration  1937\n",
      "para  0.01639809278312274 iteration  1938\n",
      "para  0.016399502611552635 iteration  1939\n",
      "para  0.016403600162995798 iteration  1940\n",
      "para  0.01638725109890413 iteration  1941\n",
      "para  0.016395453484396826 iteration  1942\n",
      "para  0.01640004217821897 iteration  1943\n",
      "para  0.016392022048186225 iteration  1944\n",
      "para  0.016399054300798847 iteration  1945\n",
      "para  0.016406659468894382 iteration  1946\n",
      "para  0.016391087850760166 iteration  1947\n",
      "para  0.01639762677895387 iteration  1948\n",
      "para  0.01640187652686903 iteration  1949\n",
      "para  0.016397584208792143 iteration  1950\n",
      "para  0.016404805344932907 iteration  1951\n",
      "para  0.01640478135882483 iteration  1952\n",
      "para  0.01640978511246564 iteration  1953\n",
      "para  0.016403910163948165 iteration  1954\n",
      "para  0.016401757235637398 iteration  1955\n",
      "para  0.016406043118960097 iteration  1956\n",
      "para  0.01639604931330593 iteration  1957\n",
      "para  0.016403528657206543 iteration  1958\n",
      "para  0.01640623156887906 iteration  1959\n",
      "para  0.016410515925218413 iteration  1960\n",
      "para  0.016395893704748702 iteration  1961\n",
      "para  0.016403637596002975 iteration  1962\n",
      "para  0.01641179067271148 iteration  1963\n",
      "para  0.016417718801147715 iteration  1964\n",
      "para  0.016403136141172385 iteration  1965\n",
      "para  0.016409491793775936 iteration  1966\n",
      "para  0.016409247971320002 iteration  1967\n",
      "para  0.016415206427363334 iteration  1968\n",
      "para  0.016402478747170487 iteration  1969\n",
      "para  0.016408636475659828 iteration  1970\n",
      "para  0.016410414941754034 iteration  1971\n",
      "para  0.016414227145298325 iteration  1972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.016409527264439193 iteration  1973\n",
      "para  0.016415204117903714 iteration  1974\n",
      "para  0.016420121217431624 iteration  1975\n",
      "para  0.016396870072061753 iteration  1976\n",
      "para  0.01640878537106086 iteration  1977\n",
      "para  0.016414744188147905 iteration  1978\n",
      "para  0.016409745247795867 iteration  1979\n",
      "para  0.01641668539733599 iteration  1980\n",
      "para  0.016424103800942405 iteration  1981\n",
      "para  0.01642374322314358 iteration  1982\n",
      "para  0.01641616058310103 iteration  1983\n",
      "para  0.01642124463210779 iteration  1984\n",
      "para  0.01640488965545016 iteration  1985\n",
      "para  0.016413793170801723 iteration  1986\n",
      "para  0.016423386499988587 iteration  1987\n",
      "para  0.016420641175664677 iteration  1988\n",
      "para  0.01642722923102775 iteration  1989\n",
      "para  0.016413109896400088 iteration  1990\n",
      "para  0.016421627477015005 iteration  1991\n",
      "para  0.016428518188911716 iteration  1992\n",
      "para  0.016436094982495406 iteration  1993\n",
      "para  0.016428515813028358 iteration  1994\n",
      "para  0.016436457759180196 iteration  1995\n",
      "para  0.016419605517221172 iteration  1996\n",
      "para  0.016429399425154596 iteration  1997\n",
      "para  0.01643433050527132 iteration  1998\n",
      "para  0.016432627667993152 iteration  1999\n",
      "para  0.016438378586516526 iteration  2000\n",
      "Cost after iteration 2000: 0.113821\n",
      "para  0.016436882777867142 iteration  2001\n",
      "para  0.01643990223393747 iteration  2002\n",
      "para  0.016442312127351068 iteration  2003\n",
      "para  0.01644074028019078 iteration  2004\n",
      "para  0.016436055106977578 iteration  2005\n",
      "para  0.016441316247937404 iteration  2006\n",
      "para  0.016427427879558566 iteration  2007\n",
      "para  0.01643498022997905 iteration  2008\n",
      "para  0.016446273951160415 iteration  2009\n",
      "para  0.016442908215590992 iteration  2010\n",
      "para  0.016446521159435165 iteration  2011\n",
      "para  0.01644072542022621 iteration  2012\n",
      "para  0.01644817051290284 iteration  2013\n",
      "para  0.016443852084370252 iteration  2014\n",
      "para  0.016449110173717325 iteration  2015\n",
      "para  0.016434813939125412 iteration  2016\n",
      "para  0.01644290342751673 iteration  2017\n",
      "para  0.0164518775632783 iteration  2018\n",
      "para  0.016448745846547402 iteration  2019\n",
      "para  0.016454842298588207 iteration  2020\n",
      "para  0.01644107151691322 iteration  2021\n",
      "para  0.01644915037316085 iteration  2022\n",
      "para  0.016455549533935965 iteration  2023\n",
      "para  0.016458921300052734 iteration  2024\n",
      "para  0.016461791177169418 iteration  2025\n",
      "para  0.016451089401691685 iteration  2026\n",
      "para  0.01645884328259899 iteration  2027\n",
      "para  0.016456148486729157 iteration  2028\n",
      "para  0.016462131030702175 iteration  2029\n",
      "para  0.016453579103770273 iteration  2030\n",
      "para  0.016460379029915616 iteration  2031\n",
      "para  0.016468049856619517 iteration  2032\n",
      "para  0.016449605860766967 iteration  2033\n",
      "para  0.016457750920642545 iteration  2034\n",
      "para  0.016462726185775274 iteration  2035\n",
      "para  0.016462504240852823 iteration  2036\n",
      "para  0.01646723446651869 iteration  2037\n",
      "para  0.0164655960797382 iteration  2038\n",
      "para  0.01647148600014587 iteration  2039\n",
      "para  0.01645969499434706 iteration  2040\n",
      "para  0.01646576199514052 iteration  2041\n",
      "para  0.016468787364119435 iteration  2042\n",
      "para  0.016469678911523615 iteration  2043\n",
      "para  0.016475481457386653 iteration  2044\n",
      "para  0.016452086763308296 iteration  2045\n",
      "para  0.016459544327102584 iteration  2046\n",
      "para  0.01646557235238048 iteration  2047\n",
      "para  0.0164693099907699 iteration  2048\n",
      "para  0.016470995494755617 iteration  2049\n",
      "para  0.016476754162194684 iteration  2050\n",
      "para  0.016463438112858803 iteration  2051\n",
      "para  0.016468837629201923 iteration  2052\n",
      "para  0.016473616612509775 iteration  2053\n",
      "para  0.016459647994285044 iteration  2054\n",
      "para  0.01646662643650668 iteration  2055\n",
      "para  0.01647154888917742 iteration  2056\n",
      "para  0.016467789265608927 iteration  2057\n",
      "para  0.016475834136017976 iteration  2058\n",
      "para  0.0164687074253936 iteration  2059\n",
      "para  0.016474660828825895 iteration  2060\n",
      "para  0.016474475645322898 iteration  2061\n",
      "para  0.016479140410566948 iteration  2062\n",
      "para  0.016475145639916006 iteration  2063\n",
      "para  0.01647887523723188 iteration  2064\n",
      "para  0.01647729622291644 iteration  2065\n",
      "para  0.01647610059173424 iteration  2066\n",
      "para  0.016481308463836265 iteration  2067\n",
      "para  0.016465103361961924 iteration  2068\n",
      "para  0.016472686473786656 iteration  2069\n",
      "para  0.016476894773735068 iteration  2070\n",
      "para  0.016483082190206184 iteration  2071\n",
      "para  0.016487772242577255 iteration  2072\n",
      "para  0.01647065077090153 iteration  2073\n",
      "para  0.016476920358640203 iteration  2074\n",
      "para  0.016481815761046886 iteration  2075\n",
      "para  0.016481444229190984 iteration  2076\n",
      "para  0.016488209300796936 iteration  2077\n",
      "para  0.016471190945053858 iteration  2078\n",
      "para  0.01647765183233248 iteration  2079\n",
      "para  0.01648322528004541 iteration  2080\n",
      "para  0.01648085479468289 iteration  2081\n",
      "para  0.016486918332839252 iteration  2082\n",
      "para  0.016486886842563574 iteration  2083\n",
      "para  0.016491177659524348 iteration  2084\n",
      "para  0.016484179880313754 iteration  2085\n",
      "para  0.016491580474540923 iteration  2086\n",
      "para  0.01648719514098789 iteration  2087\n",
      "para  0.016491574526080605 iteration  2088\n",
      "para  0.016478123417480433 iteration  2089\n",
      "para  0.016485615215395138 iteration  2090\n",
      "para  0.01649206727276568 iteration  2091\n",
      "para  0.01649415515779538 iteration  2092\n",
      "para  0.016497575558678253 iteration  2093\n",
      "para  0.016488430415802686 iteration  2094\n",
      "para  0.016494949081018936 iteration  2095\n",
      "para  0.016499174856051416 iteration  2096\n",
      "para  0.016504362474068033 iteration  2097\n",
      "para  0.016478013449158335 iteration  2098\n",
      "para  0.016485672392324544 iteration  2099\n",
      "para  0.016491809856110116 iteration  2100\n",
      "Cost after iteration 2100: 0.107839\n",
      "para  0.016496885169324824 iteration  2101\n",
      "para  0.016489463934137093 iteration  2102\n",
      "para  0.01649596928232615 iteration  2103\n",
      "para  0.016499975494570124 iteration  2104\n",
      "para  0.016504993519339747 iteration  2105\n",
      "para  0.0164793893472767 iteration  2106\n",
      "para  0.016488843208505254 iteration  2107\n",
      "para  0.016495156583735945 iteration  2108\n",
      "para  0.01650080521900189 iteration  2109\n",
      "para  0.016500805039611988 iteration  2110\n",
      "para  0.01650683865435385 iteration  2111\n",
      "para  0.016510208850024098 iteration  2112\n",
      "para  0.016497202646806236 iteration  2113\n",
      "para  0.016502354349998673 iteration  2114\n",
      "para  0.01650815500982325 iteration  2115\n",
      "para  0.016499170902375293 iteration  2116\n",
      "para  0.016505588427811562 iteration  2117\n",
      "para  0.016509894583978633 iteration  2118\n",
      "para  0.0165069505183968 iteration  2119\n",
      "para  0.016511730695075742 iteration  2120\n",
      "para  0.01650712495503749 iteration  2121\n",
      "para  0.016511965559146264 iteration  2122\n",
      "para  0.016511225705776122 iteration  2123\n",
      "para  0.01651040766614393 iteration  2124\n",
      "para  0.016513701267016574 iteration  2125\n",
      "para  0.016505565973788154 iteration  2126\n",
      "para  0.01651337122364468 iteration  2127\n",
      "para  0.016512925172805837 iteration  2128\n",
      "para  0.01651748922482461 iteration  2129\n",
      "para  0.016504182402873255 iteration  2130\n",
      "para  0.016511017386247204 iteration  2131\n",
      "para  0.01651906336315558 iteration  2132\n",
      "para  0.01651735197030981 iteration  2133\n",
      "para  0.016522505416519145 iteration  2134\n",
      "para  0.016514014900968925 iteration  2135\n",
      "para  0.016520389019004645 iteration  2136\n",
      "para  0.016526389346909198 iteration  2137\n",
      "para  0.016517777253513145 iteration  2138\n",
      "para  0.016522787077060452 iteration  2139\n",
      "para  0.016525117156835314 iteration  2140\n",
      "para  0.016524398964214235 iteration  2141\n",
      "para  0.016528738044961865 iteration  2142\n",
      "para  0.016517904308210214 iteration  2143\n",
      "para  0.016524337484886024 iteration  2144\n",
      "para  0.016529475135739873 iteration  2145\n",
      "para  0.016534274710013973 iteration  2146\n",
      "para  0.016513972982683773 iteration  2147\n",
      "para  0.01652015860234062 iteration  2148\n",
      "para  0.016525448109151967 iteration  2149\n",
      "para  0.01652714314110961 iteration  2150\n",
      "para  0.016532276389858606 iteration  2151\n",
      "para  0.01653064938410333 iteration  2152\n",
      "para  0.01653319476974403 iteration  2153\n",
      "para  0.016537129694415995 iteration  2154\n",
      "para  0.016522616860436008 iteration  2155\n",
      "para  0.01652947933706115 iteration  2156\n",
      "para  0.01653459010866489 iteration  2157\n",
      "para  0.01652984272193728 iteration  2158\n",
      "para  0.01653571697553778 iteration  2159\n",
      "para  0.016540509878589234 iteration  2160\n",
      "para  0.01652741002781126 iteration  2161\n",
      "para  0.016533612254024888 iteration  2162\n",
      "para  0.01653838988377624 iteration  2163\n",
      "para  0.016535261389505816 iteration  2164\n",
      "para  0.016542231119163708 iteration  2165\n",
      "para  0.01653684589257019 iteration  2166\n",
      "para  0.016542059010693173 iteration  2167\n",
      "para  0.01654321028192328 iteration  2168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.016548101852291414 iteration  2169\n",
      "para  0.01653450347254013 iteration  2170\n",
      "para  0.016540200718236343 iteration  2171\n",
      "para  0.016543521723199863 iteration  2172\n",
      "para  0.016547755874789113 iteration  2173\n",
      "para  0.016536274442701514 iteration  2174\n",
      "para  0.01654150856676116 iteration  2175\n",
      "para  0.0165471973935896 iteration  2176\n",
      "para  0.016542603024724177 iteration  2177\n",
      "para  0.0165477828846222 iteration  2178\n",
      "para  0.016547054348323847 iteration  2179\n",
      "para  0.016551450476041788 iteration  2180\n",
      "para  0.016548307246896817 iteration  2181\n",
      "para  0.016555644750619887 iteration  2182\n",
      "para  0.016542380412401296 iteration  2183\n",
      "para  0.01654869152465456 iteration  2184\n",
      "para  0.01655360676282633 iteration  2185\n",
      "para  0.01655428533012511 iteration  2186\n",
      "para  0.016559625586167557 iteration  2187\n",
      "para  0.016539793385115277 iteration  2188\n",
      "para  0.016548128673185964 iteration  2189\n",
      "para  0.01655426362718464 iteration  2190\n",
      "para  0.016557915599659828 iteration  2191\n",
      "para  0.01656344492155063 iteration  2192\n",
      "para  0.01654686670316247 iteration  2193\n",
      "para  0.016554365477647378 iteration  2194\n",
      "para  0.016560273244646092 iteration  2195\n",
      "para  0.016563301033940193 iteration  2196\n",
      "para  0.016560927115962847 iteration  2197\n",
      "para  0.016566081290469697 iteration  2198\n",
      "para  0.016561025380689962 iteration  2199\n",
      "para  0.016565869094947266 iteration  2200\n",
      "Cost after iteration 2200: 0.102855\n",
      "para  0.01656137204091941 iteration  2201\n",
      "para  0.01656688187277964 iteration  2202\n",
      "para  0.01656214576215866 iteration  2203\n",
      "para  0.016567441884592637 iteration  2204\n",
      "para  0.01657245297596732 iteration  2205\n",
      "para  0.016553884368794732 iteration  2206\n",
      "para  0.016560856067268974 iteration  2207\n",
      "para  0.016568601085657206 iteration  2208\n",
      "para  0.01657036817905597 iteration  2209\n",
      "para  0.0165732379887111 iteration  2210\n",
      "para  0.01656944162175453 iteration  2211\n",
      "para  0.016571618231323724 iteration  2212\n",
      "para  0.016574792684552295 iteration  2213\n",
      "para  0.016567292015176382 iteration  2214\n",
      "para  0.016571604636612502 iteration  2215\n",
      "para  0.01657593296933099 iteration  2216\n",
      "para  0.01656533847992718 iteration  2217\n",
      "para  0.016570921704623168 iteration  2218\n",
      "para  0.016575116555206285 iteration  2219\n",
      "para  0.016573863492815734 iteration  2220\n",
      "para  0.016580397695839334 iteration  2221\n",
      "para  0.016558902822381694 iteration  2222\n",
      "para  0.016566874796947944 iteration  2223\n",
      "para  0.016573163700407508 iteration  2224\n",
      "para  0.01657781839253581 iteration  2225\n",
      "para  0.016572408674771454 iteration  2226\n",
      "para  0.016577069292037123 iteration  2227\n",
      "para  0.016578957776051284 iteration  2228\n",
      "para  0.01658034988524825 iteration  2229\n",
      "para  0.016573015407985836 iteration  2230\n",
      "para  0.016579368504312124 iteration  2231\n",
      "para  0.016578862974317477 iteration  2232\n",
      "para  0.01658302097923478 iteration  2233\n",
      "para  0.01658110348331 iteration  2234\n",
      "para  0.016585815728476384 iteration  2235\n",
      "para  0.01658166517413689 iteration  2236\n",
      "para  0.016586843429722123 iteration  2237\n",
      "para  0.01658016723583491 iteration  2238\n",
      "para  0.016584909713291022 iteration  2239\n",
      "para  0.01658700022854409 iteration  2240\n",
      "para  0.016573834718098677 iteration  2241\n",
      "para  0.016578754571974094 iteration  2242\n",
      "para  0.016582964882892303 iteration  2243\n",
      "para  0.01658180497221806 iteration  2244\n",
      "para  0.016587478413448736 iteration  2245\n",
      "para  0.016590340311843487 iteration  2246\n",
      "para  0.016587192780354233 iteration  2247\n",
      "para  0.016589578658022148 iteration  2248\n",
      "para  0.016591190101631004 iteration  2249\n",
      "para  0.01658104798771943 iteration  2250\n",
      "para  0.016589293491945985 iteration  2251\n",
      "para  0.01659031373125372 iteration  2252\n",
      "para  0.01659458612754521 iteration  2253\n",
      "para  0.016597061287497047 iteration  2254\n",
      "para  0.016586784957281598 iteration  2255\n",
      "para  0.01659091959199017 iteration  2256\n",
      "para  0.016596716031020822 iteration  2257\n",
      "para  0.016572696633340836 iteration  2258\n",
      "para  0.016583820420762865 iteration  2259\n",
      "para  0.016590398616549255 iteration  2260\n",
      "para  0.016596035534090642 iteration  2261\n",
      "para  0.016595983995426358 iteration  2262\n",
      "para  0.01660046442102921 iteration  2263\n",
      "para  0.01658010456523904 iteration  2264\n",
      "para  0.01658714910357386 iteration  2265\n",
      "para  0.016592796411141128 iteration  2266\n",
      "para  0.016599330474335566 iteration  2267\n",
      "para  0.016603362918886862 iteration  2268\n",
      "para  0.01659364092461898 iteration  2269\n",
      "para  0.016598183422154154 iteration  2270\n",
      "para  0.01660214054654848 iteration  2271\n",
      "para  0.016600939208807782 iteration  2272\n",
      "para  0.01660551804655959 iteration  2273\n",
      "para  0.016599763458137188 iteration  2274\n",
      "para  0.016604339478922807 iteration  2275\n",
      "para  0.016607093019939383 iteration  2276\n",
      "para  0.01660474680661998 iteration  2277\n",
      "para  0.016610613343164493 iteration  2278\n",
      "para  0.01660695837035856 iteration  2279\n",
      "para  0.016610623988666865 iteration  2280\n",
      "para  0.0165988881832228 iteration  2281\n",
      "para  0.01660471929407975 iteration  2282\n",
      "para  0.01660958879597046 iteration  2283\n",
      "para  0.016614461542878392 iteration  2284\n",
      "para  0.01661037235043341 iteration  2285\n",
      "para  0.016613082820555146 iteration  2286\n",
      "para  0.01661658876908075 iteration  2287\n",
      "para  0.016602832669171532 iteration  2288\n",
      "para  0.016607268684476175 iteration  2289\n",
      "para  0.01661359091590262 iteration  2290\n",
      "para  0.016606737419395046 iteration  2291\n",
      "para  0.016611898106162096 iteration  2292\n",
      "para  0.01661578416172574 iteration  2293\n",
      "para  0.01660665937530785 iteration  2294\n",
      "para  0.01661234048514885 iteration  2295\n",
      "para  0.016617565293466866 iteration  2296\n",
      "para  0.016623116165354255 iteration  2297\n",
      "para  0.016622652507213603 iteration  2298\n",
      "para  0.01662731088097404 iteration  2299\n",
      "para  0.016600046931221888 iteration  2300\n",
      "Cost after iteration 2300: 0.100897\n",
      "para  0.016606659597307328 iteration  2301\n",
      "para  0.01661280258870866 iteration  2302\n",
      "para  0.016617467417916258 iteration  2303\n",
      "para  0.016620220414820006 iteration  2304\n",
      "para  0.016624935873066626 iteration  2305\n",
      "para  0.01661473772234022 iteration  2306\n",
      "para  0.016618930492021795 iteration  2307\n",
      "para  0.01662346353397532 iteration  2308\n",
      "para  0.016616324613377243 iteration  2309\n",
      "para  0.01662160126377687 iteration  2310\n",
      "para  0.016626374516669984 iteration  2311\n",
      "para  0.01662222171738275 iteration  2312\n",
      "para  0.016627760910138602 iteration  2313\n",
      "para  0.016630214229027412 iteration  2314\n",
      "para  0.01662603783691686 iteration  2315\n",
      "para  0.016629615112008417 iteration  2316\n",
      "para  0.016631458788799458 iteration  2317\n",
      "para  0.016615955239040723 iteration  2318\n",
      "para  0.016620452064874617 iteration  2319\n",
      "para  0.016625016255673166 iteration  2320\n",
      "para  0.01662808512225956 iteration  2321\n",
      "para  0.01662515919145211 iteration  2322\n",
      "para  0.016629589119582535 iteration  2323\n",
      "para  0.01663345334857358 iteration  2324\n",
      "para  0.016626834142615517 iteration  2325\n",
      "para  0.016630244559016304 iteration  2326\n",
      "para  0.016629322568743766 iteration  2327\n",
      "para  0.01663369020875116 iteration  2328\n",
      "para  0.016633132081726454 iteration  2329\n",
      "para  0.01663781404999018 iteration  2330\n",
      "para  0.016642798566323346 iteration  2331\n",
      "para  0.016615480189154434 iteration  2332\n",
      "para  0.016622586608908314 iteration  2333\n",
      "para  0.016628235819244764 iteration  2334\n",
      "para  0.01663542437047495 iteration  2335\n",
      "para  0.01663998885067965 iteration  2336\n",
      "para  0.01662942235065634 iteration  2337\n",
      "para  0.01663389079102505 iteration  2338\n",
      "para  0.01663852243111127 iteration  2339\n",
      "para  0.016636837608184324 iteration  2340\n",
      "para  0.0166419112020305 iteration  2341\n",
      "para  0.01664274619206088 iteration  2342\n",
      "para  0.016645837383014464 iteration  2343\n",
      "para  0.01664122107335619 iteration  2344\n",
      "para  0.016640533687113726 iteration  2345\n",
      "para  0.016643209471583542 iteration  2346\n",
      "para  0.016641228948378013 iteration  2347\n",
      "para  0.016642000488869303 iteration  2348\n",
      "para  0.01664532520960594 iteration  2349\n",
      "para  0.01663693649035814 iteration  2350\n",
      "para  0.016643721797609635 iteration  2351\n",
      "para  0.016644928760094897 iteration  2352\n",
      "para  0.016648488879009073 iteration  2353\n",
      "para  0.016649828539359996 iteration  2354\n",
      "para  0.016652304099960515 iteration  2355\n",
      "para  0.01664280521042171 iteration  2356\n",
      "para  0.01664729665367306 iteration  2357\n",
      "para  0.016652401724100152 iteration  2358\n",
      "para  0.016642467258136895 iteration  2359\n",
      "para  0.016647602843330465 iteration  2360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "para  0.016652732643370357 iteration  2361\n",
      "para  0.016651485787257343 iteration  2362\n",
      "para  0.016656571751532175 iteration  2363\n",
      "para  0.016651752254424956 iteration  2364\n",
      "para  0.016657901176886952 iteration  2365\n",
      "para  0.016653837051627575 iteration  2366\n",
      "para  0.016656664920078553 iteration  2367\n",
      "para  0.016653336346297606 iteration  2368\n",
      "para  0.01665812807374558 iteration  2369\n",
      "para  0.016662893172297685 iteration  2370\n",
      "para  0.016650008286549778 iteration  2371\n",
      "para  0.016655178982944368 iteration  2372\n",
      "para  0.016659948697767928 iteration  2373\n",
      "para  0.016660135891652154 iteration  2374\n",
      "para  0.01666244806354108 iteration  2375\n",
      "para  0.01666065042015322 iteration  2376\n",
      "para  0.016663838060133277 iteration  2377\n",
      "para  0.016666257540520486 iteration  2378\n",
      "para  0.01665605947949246 iteration  2379\n",
      "para  0.016662878028513562 iteration  2380\n",
      "para  0.016662607214087237 iteration  2381\n",
      "para  0.016666132731853904 iteration  2382\n",
      "para  0.016669863012629627 iteration  2383\n",
      "para  0.01665763148107337 iteration  2384\n",
      "para  0.01666362377093296 iteration  2385\n",
      "para  0.016664314860211894 iteration  2386\n",
      "para  0.01666818309247463 iteration  2387\n",
      "para  0.01667238227030764 iteration  2388\n",
      "para  0.016667129163738654 iteration  2389\n",
      "para  0.016672852482872553 iteration  2390\n",
      "para  0.016661932389575838 iteration  2391\n",
      "para  0.016664896967638187 iteration  2392\n",
      "para  0.01666737277131645 iteration  2393\n",
      "para  0.016667369459989225 iteration  2394\n",
      "para  0.016671943617779454 iteration  2395\n",
      "para  0.01666746861075305 iteration  2396\n",
      "para  0.016672417800709587 iteration  2397\n",
      "para  0.016676437130385507 iteration  2398\n",
      "para  0.016675766019726243 iteration  2399\n",
      "para  0.016679566938550598 iteration  2400\n",
      "Cost after iteration 2400: 0.092878\n",
      "para  0.016659023178600494 iteration  2401\n",
      "para  0.01666404155850109 iteration  2402\n",
      "para  0.01666946128644225 iteration  2403\n",
      "para  0.01667309897824211 iteration  2404\n",
      "para  0.016673346769513524 iteration  2405\n",
      "para  0.016678541786565575 iteration  2406\n",
      "para  0.016664048865339044 iteration  2407\n",
      "para  0.016670180708838887 iteration  2408\n",
      "para  0.016675440470905422 iteration  2409\n",
      "para  0.016679425846279718 iteration  2410\n",
      "para  0.0166725837247492 iteration  2411\n",
      "para  0.016678239924716533 iteration  2412\n",
      "para  0.01668366441391268 iteration  2413\n",
      "para  0.016687957960061558 iteration  2414\n",
      "para  0.01666195978495717 iteration  2415\n",
      "para  0.016667802495993495 iteration  2416\n",
      "para  0.01667358764922798 iteration  2417\n",
      "para  0.016678409513618014 iteration  2418\n",
      "para  0.016683396171776166 iteration  2419\n",
      "para  0.01668134041015783 iteration  2420\n",
      "para  0.01668550905153218 iteration  2421\n",
      "para  0.016684773135038057 iteration  2422\n",
      "para  0.016687810710773725 iteration  2423\n",
      "para  0.01669093326022979 iteration  2424\n",
      "para  0.016676346167140196 iteration  2425\n",
      "para  0.01668125539335262 iteration  2426\n",
      "para  0.016685857182398553 iteration  2427\n",
      "para  0.01669204739477269 iteration  2428\n",
      "para  0.016686266869220638 iteration  2429\n",
      "para  0.016690624165314458 iteration  2430\n",
      "para  0.016694471529199326 iteration  2431\n",
      "para  0.016690760138789732 iteration  2432\n",
      "para  0.016695447778977846 iteration  2433\n",
      "para  0.016698639762655103 iteration  2434\n",
      "para  0.01668709385288058 iteration  2435\n",
      "para  0.01669112596495158 iteration  2436\n",
      "para  0.016695929777977507 iteration  2437\n",
      "para  0.016694098784416717 iteration  2438\n",
      "para  0.016699761188515155 iteration  2439\n",
      "para  0.01668358610996638 iteration  2440\n",
      "para  0.01668729468286943 iteration  2441\n",
      "para  0.016692284116592977 iteration  2442\n",
      "para  0.01669401082039145 iteration  2443\n",
      "para  0.016693721402788173 iteration  2444\n",
      "para  0.016698018117708078 iteration  2445\n",
      "para  0.01670033548568156 iteration  2446\n",
      "para  0.016687997814955488 iteration  2447\n",
      "para  0.01669148909645352 iteration  2448\n",
      "para  0.016695634921510293 iteration  2449\n",
      "para  0.016696830085085462 iteration  2450\n",
      "para  0.016703560849767863 iteration  2451\n",
      "para  0.016705477333838523 iteration  2452\n",
      "para  0.016690040258626682 iteration  2453\n",
      "para  0.0166935658795674 iteration  2454\n",
      "para  0.016698305021128183 iteration  2455\n",
      "para  0.016699581965185208 iteration  2456\n",
      "para  0.016705637070979808 iteration  2457\n",
      "para  0.01670874782731095 iteration  2458\n",
      "para  0.0166969042547928 iteration  2459\n",
      "para  0.016702774766778426 iteration  2460\n",
      "para  0.01670343425288973 iteration  2461\n",
      "para  0.016706905248037078 iteration  2462\n",
      "para  0.016709182386294305 iteration  2463\n",
      "para  0.016707197142744382 iteration  2464\n",
      "para  0.016711903143872088 iteration  2465\n",
      "para  0.016712179936956575 iteration  2466\n",
      "para  0.016705339345464313 iteration  2467\n",
      "para  0.01670845320061693 iteration  2468\n",
      "para  0.016711442235045445 iteration  2469\n",
      "para  0.016710839324660384 iteration  2470\n",
      "para  0.016715202261861323 iteration  2471\n",
      "para  0.01670777139866642 iteration  2472\n",
      "para  0.01671424811331679 iteration  2473\n",
      "para  0.016713877124716434 iteration  2474\n",
      "para  0.016717126088977612 iteration  2475\n",
      "para  0.016707619830693254 iteration  2476\n",
      "para  0.01671139511769658 iteration  2477\n",
      "para  0.016717597791532094 iteration  2478\n",
      "para  0.016717746338354746 iteration  2479\n",
      "para  0.016711123110406907 iteration  2480\n",
      "para  0.016713396085427087 iteration  2481\n",
      "para  0.016711196371969016 iteration  2482\n",
      "para  0.016715676822379497 iteration  2483\n",
      "para  0.016721636912970166 iteration  2484\n",
      "para  0.01671179232433857 iteration  2485\n",
      "para  0.016715602405623822 iteration  2486\n",
      "para  0.01672020483625814 iteration  2487\n",
      "para  0.01672249298062291 iteration  2488\n",
      "para  0.016714656076733458 iteration  2489\n",
      "para  0.016721191015790116 iteration  2490\n",
      "para  0.016719283940118186 iteration  2491\n",
      "para  0.016722183337063306 iteration  2492\n",
      "para  0.0167240578160709 iteration  2493\n",
      "para  0.016723162692685443 iteration  2494\n",
      "para  0.016728565768476554 iteration  2495\n",
      "para  0.016706260877642314 iteration  2496\n",
      "para  0.016712206887178387 iteration  2497\n",
      "para  0.01671789692373305 iteration  2498\n",
      "para  0.016722321082918566 iteration  2499\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 2500, print_cost = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Cost after iteration 0**</td>\n",
    "        <td> 0.771749 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 100**</td>\n",
    "        <td> 0.672053 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **...**</td>\n",
    "        <td> ... </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> **Cost after iteration 2400**</td>\n",
    "        <td> 0.092878 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9856459330143539\n"
     ]
    }
   ],
   "source": [
    "pred_train = predict(train_x, train_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "    <td>\n",
    "    **Train Accuracy**\n",
    "    </td>\n",
    "    <td>\n",
    "    0.985645933014\n",
    "    </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "pred_test = predict(test_x, test_y, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "        <td> **Test Accuracy**</td>\n",
    "        <td> 0.8 </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! It seems that your 4-layer neural network has better performance (80%) than your 2-layer neural network (72%) on the same test set. \n",
    "\n",
    "This is good performance for this task. Nice job! \n",
    "\n",
    "Though in the next course on \"Improving deep neural networks\" you will learn how to obtain even higher accuracy by systematically searching for better hyperparameters (learning_rate, layers_dims, num_iterations, and others you'll also learn in the next course). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6) Results Analysis\n",
    "\n",
    "First, let's take a look at some images the L-layer model labeled incorrectly. This will show a few mislabeled images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_mislabeled_images(classes, test_x, test_y, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A few types of images the model tends to do poorly on include:** \n",
    "- Cat body in an unusual position\n",
    "- Cat appears against a background of a similar color\n",
    "- Unusual cat color and species\n",
    "- Camera Angle\n",
    "- Brightness of the picture\n",
    "- Scale variation (cat is very large or small in image) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Test with your own image (optional/ungraded exercise) ##\n",
    "\n",
    "Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:\n",
    "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "    2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    3. Change your image's name in the following code\n",
    "    4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## START CODE HERE ##\n",
    "my_image = \"my_image.jpg\" # change this to the name of your image file \n",
    "my_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\n",
    "## END CODE HERE ##\n",
    "\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\n",
    "my_image = my_image/255.\n",
    "my_predicted_image = predict(my_image, my_label_y, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**:\n",
    "\n",
    "- for auto-reloading external module: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "TSPse",
   "launcher_item_id": "24mxX"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
